@article{aaronson2015,
  title = {Read the Fine Print},
  author = {Aaronson, Scott},
  date = {2015},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {11},
  number = {4},
  pages = {291--293},
  issn = {1745-2473, 1745-2481},
  doi = {10.1038/nphys3272},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/WVX63N4D/Aaronson - 2015 - Read the fine print.pdf}
}

@article{abbas2021,
  title = {The Power of Quantum Neural Networks},
  author = {Abbas, Amira and Sutter, David and Zoufal, Christa and Lucchi, Aurelien and Figalli, Alessio and Woerner, Stefan},
  date = {2021},
  journaltitle = {Nature Computational Science},
  shortjournal = {Nat Comput Sci},
  volume = {1},
  number = {6},
  pages = {403--409},
  issn = {2662-8457},
  doi = {10.1038/s43588-021-00084-1},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/96CUPR25/Abbas et al. - 2021 - The power of quantum neural networks.pdf}
}

@online{adamoptimiser,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  date = {2017},
  number = {arXiv:1412.6980},
  eprint = {arXiv:1412.6980},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.1412.6980},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/boyesjo/Zotero/storage/2V68NWN2/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;/Users/boyesjo/Zotero/storage/T39LPLSU/1412.html}
}

@inproceedings{agrawal2013,
  title = {Further {{Optimal Regret Bounds}} for {{Thompson Sampling}}},
  booktitle = {Proceedings of the {{Sixteenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Agrawal, Shipra and Goyal, Navin},
  date = {2013},
  pages = {99--107},
  publisher = {{PMLR}},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v31/agrawal13a.html},
  abstract = {Thompson Sampling is one of the oldest heuristics for multi-armed bandit problems. It is a randomized algorithm based on Bayesian ideas, and has recently generated significant interest after several studies demonstrated it to have comparable or better empirical performance compared to the state of the art methods. In this paper, we provide a novel regret analysis for Thompson Sampling that proves the first near-optimal problem-independent  bound of O(\textbackslash sqrtNT\textbackslash ln T) on the expected regret of this algorithm. Our novel martingale-based analysis techniques are conceptually simple, and easily extend to distributions other than the Beta distribution. For the version of Thompson Sampling that uses Gaussian priors, we prove a problem-independent bound of O(\textbackslash sqrtNT\textbackslash ln N) on the expected regret, and demonstrate the optimality of this bound by providing a matching lower bound. This lower bound of Ω(\textbackslash sqrtNT\textbackslash ln N) is the first lower bound on the performance of a natural version of Thompson Sampling that is away from the general lower bound of O(\textbackslash sqrtNT) for the multi-armed bandit problem. Our near-optimal problem-independent bounds for Thompson Sampling solve a COLT 2012 open problem of Chapelle and Li. Additionally, our techniques simultaneously provide the optimal problem-dependent bound of (1+ε)\textbackslash sum\_i \textbackslash frac\textbackslash ln Td(\textbackslash mu\_i, \textbackslash mu\_1)+O(\textbackslash fracNε\^2) on the expected regret.  The optimal problem-dependent regret bound for this problem was first proven recently by Kaufmann et al. [2012].},
  eventtitle = {Artificial {{Intelligence}} and {{Statistics}}},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/JN2W343P/Agrawal and Goyal - 2013 - Further Optimal Regret Bounds for Thompson Samplin.pdf}
}

@article{agrawal2017,
  title = {Near-{{Optimal Regret Bounds}} for {{Thompson Sampling}}},
  author = {Agrawal, Shipra and Goyal, Navin},
  date = {2017},
  journaltitle = {Journal of the ACM},
  shortjournal = {J. ACM},
  volume = {64},
  number = {5},
  pages = {30:1--30:24},
  issn = {0004-5411},
  doi = {10.1145/3088510},
  abstract = {Thompson Sampling (TS) is one of the oldest heuristics for multiarmed bandit problems. It is a randomized algorithm based on Bayesian ideas and has recently generated significant interest after several studies demonstrated that it has favorable empirical performance compared to the state-of-the-art methods. In this article, a novel and almost tight martingale-based regret analysis for Thompson Sampling is presented. Our technique simultaneously yields both problem-dependent and problem-independent bounds: (1) the first near-optimal problem-independent bound of O(√ NT ln T) on the expected regret and (2) the optimal problem-dependent bound of (1 + ϵ)Σi ln T / d(μi,μ1) + O(N/ϵ2) on the expected regret (this bound was first proven by Kaufmann et al. (2012b)). Our technique is conceptually simple and easily extends to distributions other than the Beta distribution used in the original TS algorithm. For the version of TS that uses Gaussian priors, we prove a problem-independent bound of O(√ NT ln N) on the expected regret and show the optimality of this bound by providing a matching lower bound. This is the first lower bound on the performance of a natural version of Thompson Sampling that is away from the general lower bound of Ω (√ NT) for the multiarmed bandit problem.},
  keywords = {Multi-armed bandits}
}

@article{arute2019,
  title = {Quantum Supremacy Using a Programmable Superconducting Processor},
  author = {Arute, Frank and Arya, Kunal and Babbush, Ryan and Bacon, Dave and Bardin, Joseph C. and Barends, Rami and Biswas, Rupak and Boixo, Sergio and Brandao, Fernando G. S. L. and Buell, David A. and Burkett, Brian and Chen, Yu and Chen, Zijun and Chiaro, Ben and Collins, Roberto and Courtney, William and Dunsworth, Andrew and Farhi, Edward and Foxen, Brooks and Fowler, Austin and Gidney, Craig and Giustina, Marissa and Graff, Rob and Guerin, Keith and Habegger, Steve and Harrigan, Matthew P. and Hartmann, Michael J. and Ho, Alan and Hoffmann, Markus and Huang, Trent and Humble, Travis S. and Isakov, Sergei V. and Jeffrey, Evan and Jiang, Zhang and Kafri, Dvir and Kechedzhi, Kostyantyn and Kelly, Julian and Klimov, Paul V. and Knysh, Sergey and Korotkov, Alexander and Kostritsa, Fedor and Landhuis, David and Lindmark, Mike and Lucero, Erik and Lyakh, Dmitry and Mandrà, Salvatore and McClean, Jarrod R. and McEwen, Matthew and Megrant, Anthony and Mi, Xiao and Michielsen, Kristel and Mohseni, Masoud and Mutus, Josh and Naaman, Ofer and Neeley, Matthew and Neill, Charles and Niu, Murphy Yuezhen and Ostby, Eric and Petukhov, Andre and Platt, John C. and Quintana, Chris and Rieffel, Eleanor G. and Roushan, Pedram and Rubin, Nicholas C. and Sank, Daniel and Satzinger, Kevin J. and Smelyanskiy, Vadim and Sung, Kevin J. and Trevithick, Matthew D. and Vainsencher, Amit and Villalonga, Benjamin and White, Theodore and Yao, Z. Jamie and Yeh, Ping and Zalcman, Adam and Neven, Hartmut and Martinis, John M.},
  date = {2019},
  journaltitle = {Nature},
  volume = {574},
  number = {7779},
  pages = {505--510},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1666-5},
  abstract = {The promise of quantum computers is that certain computational tasks might be executed exponentially faster on a quantum processor than on a classical processor1. A fundamental challenge is to build a high-fidelity processor capable of running quantum algorithms in an exponentially large computational space. Here we report the use of a processor with programmable superconducting qubits2–7 to create quantum states on 53 qubits, corresponding to a computational state-space of dimension 253 (about 1016). Measurements from repeated experiments sample the resulting probability distribution, which we verify using classical simulations. Our Sycamore processor takes about 200 seconds to sample one instance of a quantum circuit a million times—our benchmarks currently indicate that the equivalent task for a state-of-the-art classical supercomputer would take approximately 10,000 years. This dramatic increase in speed compared to all known classical algorithms is an experimental realization of quantum supremacy8–14 for this specific computational task, heralding a much-anticipated computing paradigm.},
  issue = {7779},
  langid = {english},
  keywords = {Quantum information,Quantum physics},
  file = {/Users/boyesjo/Zotero/storage/EKPZKACJ/Arute et al. - 2019 - Quantum supremacy using a programmable superconduc.pdf;/Users/boyesjo/Zotero/storage/XZJ3VNCC/s41586-019-1666-5.html}
}

@article{audibert2009,
  title = {Minimax Policies for Adversarial and Stochastic Bandits},
  author = {Audibert, Jean-Yves and Bubeck, Sëbastien},
  date = {2009},
  journaltitle = {Colt},
  volume = {7},
  pages = {217--226},
  file = {/Users/boyesjo/Zotero/storage/TV3QVATT/Audibert and Bubeck - 2009 - Minimax policies for adversarial and stochastic ba.pdf}
}

@article{audibert2009a,
  title = {Exploration–Exploitation Tradeoff Using Variance Estimates in Multi-Armed Bandits},
  author = {Audibert, Jean-Yves and Munos, Rémi and Szepesvári, Csaba},
  date = {2009},
  journaltitle = {Theoretical Computer Science},
  shortjournal = {Theoretical Computer Science},
  volume = {410},
  number = {19},
  pages = {1876--1902},
  issn = {03043975},
  doi = {10.1016/j.tcs.2009.01.016},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/3J7QASBY/Audibert et al. - 2009 - Exploration–exploitation tradeoff using variance e.pdf}
}

@inproceedings{auer1995,
  title = {Gambling in a rigged casino: the adversarial multi-armed bandit problem},
  shorttitle = {Gambling in a rigged casino},
  booktitle = {Annual Symposium on Foundations of Computer Science - Proceedings},
  author = {Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E.},
  date = {1995},
  pages = {322--331},
  issn = {0272-5428},
  url = {https://collaborate.princeton.edu/en/publications/gambling-in-a-rigged-casino-the-adversarial-multi-armed-bandit-pr},
  eventtitle = {Proceedings of the 1995 IEEE 36th Annual Symposium on Foundations of Computer Science},
  langid = {English (US)},
  file = {/Users/boyesjo/Zotero/storage/37Y6V6EL/gambling-in-a-rigged-casino-the-adversarial-multi-armed-bandit-pr.html}
}

@article{auer2002,
  title = {Finite-Time {{Analysis}} of the {{Multiarmed Bandit Problem}}},
  author = {Auer, Peter and Cesa-Bianchi, Nicolò and Fischer, Paul},
  date = {2002},
  journaltitle = {Machine Learning},
  shortjournal = {Machine Learning},
  volume = {47},
  number = {2},
  pages = {235--256},
  issn = {1573-0565},
  doi = {10.1023/A:1013689704352},
  abstract = {Reinforcement learning policies face the exploration versus exploitation dilemma, i.e. the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible. A popular measure of a policy's success in addressing this dilemma is the regret, that is the loss due to the fact that the globally optimal policy is not followed all the times. One of the simplest examples of the exploration/exploitation dilemma is the multi-armed bandit problem. Lai and Robbins were the first ones to show that the regret for this problem has to grow at least logarithmically in the number of plays. Since then, policies which asymptotically achieve this regret have been devised by Lai and Robbins and many others. In this work we show that the optimal logarithmic regret is also achievable uniformly over time, with simple and efficient policies, and for all reward distributions with bounded support.},
  langid = {english},
  keywords = {adaptive allocation rules,bandit problems,finite horizon regret},
  file = {/Users/boyesjo/Zotero/storage/P3T6NJEJ/Auer et al. - 2002 - Finite-time Analysis of the Multiarmed Bandit Prob.pdf}
}

@article{auer2002a,
  title = {The {{Nonstochastic Multiarmed Bandit Problem}}},
  author = {Auer, Peter and Cesa-Bianchi, Nicolò and Freund, Yoav and Schapire, Robert E.},
  date = {2002},
  journaltitle = {SIAM Journal on Computing},
  shortjournal = {SIAM J. Comput.},
  volume = {32},
  number = {1},
  pages = {48--77},
  issn = {0097-5397, 1095-7111},
  doi = {10.1137/S0097539701398375},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/JLCQVUXC/Auer et al. - 2002 - The Nonstochastic Multiarmed Bandit Problem.pdf}
}

@article{austin2012,
  title = {Quantum {{Monte Carlo}} and {{Related Approaches}}},
  author = {Austin, Brian M. and Zubarev, Dmitry Yu. and Lester, William A.},
  date = {2012},
  journaltitle = {Chemical Reviews},
  shortjournal = {Chem. Rev.},
  volume = {112},
  number = {1},
  pages = {263--288},
  issn = {0009-2665, 1520-6890},
  doi = {10.1021/cr2001564},
  langid = {english}
}

@article{bausch2020,
  title = {Recurrent Quantum Neural Networks},
  author = {Bausch, Johannes},
  date = {2020},
  journaltitle = {Advances in neural information processing systems},
  volume = {33},
  pages = {1368--1379},
  file = {/Users/boyesjo/Zotero/storage/JYBZ32M7/Bausch - 2020 - Recurrent quantum neural networks.pdf}
}

@article{benedetti2019,
  title = {Parameterized Quantum Circuits as Machine Learning Models},
  author = {Benedetti, Marcello and Lloyd, Erika and Sack, Stefan and Fiorentini, Mattia},
  date = {2019},
  journaltitle = {Quantum Science and Technology},
  shortjournal = {Quantum Sci. Technol.},
  volume = {4},
  number = {4},
  pages = {043001},
  issn = {2058-9565},
  doi = {10.1088/2058-9565/ab4eb5},
  abstract = {Abstract             Hybrid quantum–classical systems make it possible to utilize existing quantum computers to their fullest extent. Within this framework, parameterized quantum circuits can be regarded as machine learning models with remarkable expressive power. This Review presents the components of these models and discusses their application to a variety of data-driven tasks, such as supervised learning and generative modeling. With an increasing number of experimental demonstrations carried out on actual quantum hardware and with software being actively developed, this rapidly growing field is poised to have a broad spectrum of real-world applications.},
  file = {/Users/boyesjo/Zotero/storage/NABSBMM9/Benedetti et al. - 2019 - Parameterized quantum circuits as machine learning.pdf}
}

@article{besson2018,
  title = {What {{Doubling Tricks Can}} and {{Can}}'t {{Do}} for {{Multi-Armed Bandits}}},
  author = {Besson, Lilian and Kaufmann, Emilie},
  date = {2018},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1803.06971},
  abstract = {An online reinforcement learning algorithm is anytime if it does not need to know in advance the horizon T of the experiment. A well-known technique to obtain an anytime algorithm from any non-anytime algorithm is the "Doubling Trick". In the context of adversarial or stochastic multi-armed bandits, the performance of an algorithm is measured by its regret, and we study two families of sequences of growing horizons (geometric and exponential) to generalize previously known results that certain doubling tricks can be used to conserve certain regret bounds. In a broad setting, we prove that a geometric doubling trick can be used to conserve (minimax) bounds in \$R\textbackslash\_T = O(\textbackslash sqrt\{T\})\$ but cannot conserve (distribution-dependent) bounds in \$R\textbackslash\_T = O(\textbackslash log T)\$. We give insights as to why exponential doubling tricks may be better, as they conserve bounds in \$R\textbackslash\_T = O(\textbackslash log T)\$, and are close to conserving bounds in \$R\textbackslash\_T = O(\textbackslash sqrt\{T\})\$.},
  version = {1},
  keywords = {FOS: Computer and information sciences,FOS: Mathematics,Machine Learning (cs.LG),Machine Learning (stat.ML),Statistics Theory (math.ST)}
}

@article{bharti2022,
  title = {Noisy Intermediate-Scale Quantum Algorithms},
  author = {Bharti, Kishor and Cervera-Lierta, Alba and Kyaw, Thi Ha and Haug, Tobias and Alperin-Lea, Sumner and Anand, Abhinav and Degroote, Matthias and Heimonen, Hermanni and Kottmann, Jakob S. and Menke, Tim and Mok, Wai-Keong and Sim, Sukin and Kwek, Leong-Chuan and Aspuru-Guzik, Alán},
  date = {2022},
  journaltitle = {Reviews of Modern Physics},
  shortjournal = {Rev. Mod. Phys.},
  volume = {94},
  number = {1},
  pages = {015004},
  issn = {0034-6861, 1539-0756},
  doi = {10.1103/RevModPhys.94.015004},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/R7BI9MGW/Bharti et al. - 2022 - Noisy intermediate-scale quantum algorithms.pdf}
}

@inproceedings{bouneffouf2017,
  title = {Context {{Attentive Bandits}}: {{Contextual Bandit}} with {{Restricted Context}}},
  shorttitle = {Context {{Attentive Bandits}}},
  author = {Bouneffouf, Djallel and Rish, Irina and Cecchi, Guillermo and Feraud, Raphaël},
  date = {2017-08-22},
  doi = {10.24963/ijcai.2017/203},
  abstract = {We consider a novel formulation of the multi-armed bandit model, which we call the contextual bandit with restricted context, where only a limited number of features can be accessed by the learner at every iteration. This novel formulation is motivated by different online problems arising in clinical trials, recommender systems and attention modeling. Herein, we adapt the standard multi-armed bandit algorithm known as Thompson Sampling to take advantage of our restricted context setting, and propose two novel algorithms, called the Thompson Sampling with Restricted Context(TSRC) and the Windows Thompson Sampling with Restricted Context(WTSRC), for handling stationary and nonstationary environments, respectively. Our empirical results demonstrate advantages of the proposed approaches on several real-life datasets},
  file = {/Users/boyesjo/Zotero/storage/KYV4IWRA/Bouneffouf et al. - 2017 - Context Attentive Bandits Contextual Bandit with .pdf}
}

@inproceedings{bouneffouf2020,
  title = {Survey on {{Applications}} of {{Multi-Armed}} and {{Contextual Bandits}}},
  booktitle = {2020 {{IEEE Congress}} on {{Evolutionary Computation}} ({{CEC}})},
  author = {Bouneffouf, Djallel and Rish, Irina and Aggarwal, Charu},
  date = {2020},
  pages = {1--8},
  publisher = {{IEEE}},
  location = {{Glasgow, United Kingdom}},
  doi = {10.1109/CEC48606.2020.9185782},
  eventtitle = {2020 {{IEEE Congress}} on {{Evolutionary Computation}} ({{CEC}})},
  isbn = {978-1-72816-929-3},
  keywords = {Bandits,Meta},
  file = {/Users/boyesjo/Zotero/storage/QNJKBFQ6/Bouneffouf et al. - 2020 - Survey on Applications of Multi-Armed and Contextu.pdf}
}

@article{brahmachari2023,
  title = {Quantum Contextual Bandits and Recommender Systems for Quantum Data},
  author = {Brahmachari, Shrigyan and Lumbreras, Josep and Tomamichel, Marco},
  date = {2023},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2301.13524},
  abstract = {We study a recommender system for quantum data using the linear contextual bandit framework. In each round, a learner receives an observable (the context) and has to recommend from a finite set of unknown quantum states (the actions) which one to measure. The learner has the goal of maximizing the reward in each round, that is the outcome of the measurement on the unknown state. Using this model we formulate the low energy quantum state recommendation problem where the context is a Hamiltonian and the goal is to recommend the state with the lowest energy. For this task, we study two families of contexts: the Ising model and a generalized cluster model. We observe that if we interpret the actions as different phases of the models then the recommendation is done by classifying the correct phase of the given Hamiltonian and the strategy can be interpreted as an online quantum phase classifier.},
  version = {1},
  keywords = {FOS: Computer and information sciences,FOS: Physical sciences,Information Retrieval (cs.IR),Machine Learning (cs.LG),Quantum Physics (quant-ph)}
}

@incollection{brassard2002,
  title = {Quantum Amplitude Amplification and Estimation},
  booktitle = {Contemporary {{Mathematics}}},
  author = {Brassard, Gilles and Høyer, Peter and Mosca, Michele and Tapp, Alain},
  editor = {Lomonaco, Samuel J. and Brandt, Howard E.},
  date = {2002},
  volume = {305},
  pages = {53--74},
  publisher = {{American Mathematical Society}},
  location = {{Providence, Rhode Island}},
  doi = {10.1090/conm/305/05215},
  isbn = {978-0-8218-2140-4 978-0-8218-7895-8},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/PRBU35NU/Brassard et al. - 2002 - Quantum amplitude amplification and estimation.pdf}
}

@article{bubeck2012,
  title = {Regret {{Analysis}} of {{Stochastic}} and {{Nonstochastic Multi-armed Bandit Problems}}},
  author = {Bubeck, Sébastien},
  date = {2012},
  journaltitle = {Foundations and Trends® in Machine Learning},
  shortjournal = {FNT in Machine Learning},
  volume = {5},
  number = {1},
  pages = {1--122},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000024},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/D7CI53CR/Bubeck - 2012 - Regret Analysis of Stochastic and Nonstochastic Mu.pdf}
}

@unpublished{cao2017,
  title = {Quantum {{Neuron}}: An Elementary Building Block for Machine Learning on Quantum Computers},
  shorttitle = {Quantum {{Neuron}}},
  author = {Cao, Yudong and Guerreschi, Gian Giacomo and Aspuru-Guzik, Alán},
  date = {2017},
  eprint = {1711.11240},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1711.11240},
  abstract = {Even the most sophisticated artificial neural networks are built by aggregating substantially identical units called neurons. A neuron receives multiple signals, internally combines them, and applies a non-linear function to the resulting weighted sum. Several attempts to generalize neurons to the quantum regime have been proposed, but all proposals collided with the difficulty of implementing non-linear activation functions, which is essential for classical neurons, due to the linear nature of quantum mechanics. Here we propose a solution to this roadblock in the form of a small quantum circuit that naturally simulates neurons with threshold activation. Our quantum circuit defines a building block, the "quantum neuron", that can reproduce a variety of classical neural network constructions while maintaining the ability to process superpositions of inputs and preserve quantum coherence and entanglement. In the construction of feedforward networks of quantum neurons, we provide numerical evidence that the network not only can learn a function when trained with superposition of inputs and the corresponding output, but that this training suffices to learn the function on all individual inputs separately. When arranged to mimic Hopfield networks, quantum neural networks exhibit properties of associative memory. Patterns are encoded using the simple Hebbian rule for the weights and we demonstrate attractor dynamics from corrupted inputs. Finally, the fact that our quantum model closely captures (traditional) neural network dynamics implies that the vast body of literature and results on neural networks becomes directly relevant in the context of quantum machine learning.},
  version = {1},
  keywords = {FOS: Computer and information sciences,FOS: Physical sciences,Neural and Evolutionary Computing (cs.NE),Quantum Physics (quant-ph)}
}

@article{casale2020,
  title = {Quantum Bandits},
  author = {Casalé, Balthazar and Di Molfetta, Giuseppe and Kadri, Hachem and Ralaivola, Liva},
  date = {2020},
  journaltitle = {Quantum Machine Intelligence},
  shortjournal = {Quantum Mach. Intell.},
  volume = {2},
  number = {1},
  pages = {11},
  issn = {2524-4906, 2524-4914},
  doi = {10.1007/s42484-020-00024-8},
  langid = {english},
  keywords = {Bandits,quantum computation},
  file = {/Users/boyesjo/Zotero/storage/NG2V63HG/s42484-020-00024-8.pdf}
}

@article{ceperley1986,
  title = {Quantum {{Monte Carlo}}},
  author = {Ceperley, David and Alder, Berni},
  date = {1986},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {231},
  number = {4738},
  pages = {555--560},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.231.4738.555},
  langid = {english}
}

@article{cerezo2021,
  title = {Variational Quantum Algorithms},
  author = {Cerezo, Marco and Arrasmith, Andrew and Babbush, Ryan and Benjamin, Simon C. and Endo, Suguru and Fujii, Keisuke and McClean, Jarrod R. and Mitarai, Kosuke and Yuan, Xiao and Cincio, Lukasz and Coles, Patrick J.},
  date = {2021},
  journaltitle = {Nature Reviews Physics},
  shortjournal = {Nat Rev Phys},
  volume = {3},
  number = {9},
  pages = {625--644},
  issn = {2522-5820},
  doi = {10.1038/s42254-021-00348-9},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/BIYJNQX6/Cerezo et al. - 2021 - Variational quantum algorithms.pdf}
}

@article{cerezo2021a,
  title = {Cost Function Dependent Barren Plateaus in Shallow Parametrized Quantum Circuits},
  author = {Cerezo, Marco and Sone, Akira and Volkoff, Tyler and Cincio, Lukasz and Coles, Patrick J.},
  date = {2021},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {1791},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-21728-w},
  abstract = {Variational quantum algorithms (VQAs) optimize the parameters θ of a parametrized quantum circuit V(θ) to minimize a cost function C. While VQAs may enable practical applications of noisy quantum computers, they are nevertheless heuristic methods with unproven scaling. Here, we rigorously prove two results, assuming V(θ) is an alternating layered ansatz composed of blocks forming local 2-designs. Our first result states that defining C in terms of global observables leads to exponentially vanishing gradients (i.e., barren plateaus) even when V(θ) is shallow. Hence, several VQAs in the literature must revise their proposed costs. On the other hand, our second result states that defining C with local observables leads to at worst a polynomially vanishing gradient, so long as the depth of V(θ) is \$\$\{\textbackslash mathcal\{O\}\}(\textbackslash mathrm\{log\}\textbackslash,n)\$\$. Our results establish a connection between locality and trainability. We illustrate these ideas with large-scale simulations, up to 100 qubits, of a quantum autoencoder implementation.},
  issue = {1},
  langid = {english},
  keywords = {Information theory and computation,Mathematics and computing,Quantum information,Quantum physics},
  file = {/Users/boyesjo/Zotero/storage/BTHPGEA7/Cerezo et al. - 2021 - Cost function dependent barren plateaus in shallow.pdf;/Users/boyesjo/Zotero/storage/ZAXWQH63/s41467-021-21728-w.html}
}

@article{cerezo2022,
  title = {Challenges and Opportunities in Quantum Machine Learning},
  author = {Cerezo, Marco and Verdon, Guillaume and Huang, Hsin-Yuan and Cincio, Lukasz and Coles, Patrick J.},
  date = {2022},
  journaltitle = {Nature Computational Science},
  shortjournal = {Nat Comput Sci},
  issn = {2662-8457},
  doi = {10.1038/s43588-022-00311-3},
  langid = {english}
}

@article{chen2020,
  title = {Variational {{Quantum Circuits}} for {{Deep Reinforcement Learning}}},
  author = {Chen, Samuel Yen-Chi and Yang, Chao-Han Huck and Qi, Jun and Chen, Pin-Yu and Ma, Xiaoli and Goan, Hsi-Sheng},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {141007--141024},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3010470},
  abstract = {The state-of-the-art machine learning approaches are based on classical von Neumann computing architectures and have been widely used in many industrial and academic domains. With the recent development of quantum computing, researchers and tech-giants have attempted new quantum circuits for machine learning tasks. However, the existing quantum computing platforms are hard to simulate classical deep learning models or problems because of the intractability of deep quantum circuits. Thus, it is necessary to design feasible quantum algorithms for quantum machine learning for noisy intermediate scale quantum (NISQ) devices. This work explores variational quantum circuits for deep reinforcement learning. Specifically, we reshape classical deep reinforcement learning algorithms like experience replay and target network into a representation of variational quantum circuits. Moreover, we use a quantum information encoding scheme to reduce the number of model parameters compared to classical neural networks. To the best of our knowledge, this work is the first proof-of-principle demonstration of variational quantum circuits to approximate the deep Q-value function for decision-making and policy-selection reinforcement learning with experience replay and target network. Besides, our variational quantum circuits can be deployed in many near-term NISQ machines.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Communication network,Decision making,deep reinforcement learning,Learning (artificial intelligence),Machine learning,Neural networks,noisy intermediate scale quantum,Physics,quantum computing,Quantum computing,quantum information processing,quantum machine learning,Standards,variational quantum circuits},
  file = {/Users/boyesjo/Zotero/storage/IYC58LUX/Chen et al. - 2020 - Variational Quantum Circuits for Deep Reinforcemen.pdf;/Users/boyesjo/Zotero/storage/YX3ET89J/9144562.html}
}

@article{ciliberto2018,
  title = {Quantum Machine Learning: A Classical Perspective},
  shorttitle = {Quantum Machine Learning},
  author = {Ciliberto, Carlo and Herbster, Mark and Ialongo, Alessandro Davide and Pontil, Massimiliano and Rocchetto, Andrea and Severini, Simone and Wossnig, Leonard},
  date = {2018},
  journaltitle = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  shortjournal = {Proc. R. Soc. A.},
  volume = {474},
  number = {2209},
  pages = {20170551},
  issn = {1364-5021, 1471-2946},
  doi = {10.1098/rspa.2017.0551},
  abstract = {Recently, increased computational power and data availability, as well as algorithmic advances, have led machine learning (ML) techniques to impressive results in regression, classification, data generation and reinforcement learning tasks. Despite these successes, the proximity to the physical limits of chip fabrication alongside the increasing size of datasets is motivating a growing number of researchers to explore the possibility of harnessing the power of quantum computation to speed up classical ML algorithms. Here we review the literature in quantum ML and discuss perspectives for a mixed readership of classical ML and quantum computation experts. Particular emphasis will be placed on clarifying the limitations of quantum algorithms, how they compare with their best classical counterparts and why quantum resources are expected to provide advantages for learning problems. Learning in the presence of noise and certain computationally hard problems in ML are identified as promising directions for the field. Practical questions, such as how to upload classical data into quantum form, will also be addressed.},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/NGEIDDP5/Ciliberto et al. - 2018 - Quantum machine learning a classical perspective.pdf}
}

@article{cong2019,
  title = {Quantum Convolutional Neural Networks},
  author = {Cong, Iris and Choi, Soonwon and Lukin, Mikhail D.},
  date = {2019},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {15},
  number = {12},
  pages = {1273--1278},
  issn = {1745-2473, 1745-2481},
  doi = {10.1038/s41567-019-0648-8},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/YWN6VJI6/Cong et al. - 2019 - Quantum convolutional neural networks.pdf}
}

@article{dagum2000,
  title = {An {{Optimal Algorithm}} for {{Monte Carlo Estimation}}},
  author = {Dagum, Paul and Karp, Richard and Luby, Michael and Ross, Sheldon},
  date = {2000},
  journaltitle = {SIAM Journal on Computing},
  shortjournal = {SIAM J. Comput.},
  volume = {29},
  number = {5},
  pages = {1484--1496},
  issn = {0097-5397, 1095-7111},
  doi = {10.1137/S0097539797315306},
  langid = {english}
}

@unpublished{daulton2019,
  title = {Facebook Talk at the {{Netflix ML Platform Meetup}} ({{Part}} 3)},
  author = {Daulton, Sam},
  date = {2019},
  url = {https://youtu.be/A-JJvYaBPUU},
  eventtitle = {Machine {{Learning Platform}}},
  venue = {{Los Gatos}}
}

@unpublished{dervovic2018,
  title = {Quantum Linear Systems Algorithms: A Primer},
  shorttitle = {Quantum Linear Systems Algorithms},
  author = {Dervovic, Danial and Herbster, Mark and Mountney, Peter and Severini, Simone and Usher, Naïri and Wossnig, Leonard},
  date = {2018},
  eprint = {1802.08227},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1802.08227},
  abstract = {The Harrow-Hassidim-Lloyd (HHL) quantum algorithm for sampling from the solution of a linear system provides an exponential speed-up over its classical counterpart. The problem of solving a system of linear equations has a wide scope of applications, and thus HHL constitutes an important algorithmic primitive. In these notes, we present the HHL algorithm and its improved versions in detail, including explanations of the constituent sub- routines. More specifically, we discuss various quantum subroutines such as quantum phase estimation and amplitude amplification, as well as the important question of loading data into a quantum computer, via quantum RAM. The improvements to the original algorithm exploit variable-time amplitude amplification as well as a method for implementing linear combinations of unitary operations (LCUs) based on a decomposition of the operators using Fourier and Chebyshev series. Finally, we discuss a linear solver based on the quantum singular value estimation (QSVE) subroutine.},
  version = {1},
  keywords = {Data Structures and Algorithms (cs.DS),FOS: Computer and information sciences,FOS: Mathematics,FOS: Physical sciences,Numerical Analysis (math.NA),Quantum Physics (quant-ph)}
}

@inproceedings{dunjko2017,
  title = {Advances in Quantum Reinforcement Learning},
  booktitle = {2017 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  author = {Dunjko, Vedran and Taylor, Jacob M. and Briegel, Hans J.},
  date = {2017},
  pages = {282--287},
  doi = {10.1109/SMC.2017.8122616},
  abstract = {In recent times, there has been much interest in quantum enhancements of machine learning, specifically in the context of data mining and analysis. Reinforcement learning, an interactive form of learning, is, in turn, vital in artificial intelligence-type applications. Also in this case, quantum mechanics was shown to be useful, in certain instances. Here, we elucidate these results, and show that quantum enhancements can be achieved in a new setting: the setting of learning models which learn how to improve themselves - that is, those that metalearn. While not all learning models meta-learn, all non-trivial models have the potential of being "lifted", enhanced, to meta-learning models. Our results show that also such models can be quantum-enhanced to make even better learners. In parallel, we address one of the bottlenecks of current quantum reinforcement learning approaches: the need for so-called oracularized variants of task environments. Here we elaborate on a method which realizes these variants, with minimal changes in the setting, and with no corruption of the operative specification of the environments. This result may be important in near-term experimental demonstrations of quantum reinforcement learning.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  keywords = {Computational complexity,History,Learning (artificial intelligence),quantum computation,Random access memory,Registers,reinforcement learning,Standards},
  file = {/Users/boyesjo/Zotero/storage/3DH7N83S/Dunjko et al. - 2017 - Advances in quantum reinforcement learning.pdf;/Users/boyesjo/Zotero/storage/JILGRL3L/8122616.html}
}

@article{endo2021,
  title = {Hybrid {{Quantum-Classical Algorithms}} and {{Quantum Error Mitigation}}},
  author = {Endo, Suguru and Cai, Zhenyu and Benjamin, Simon C. and Yuan, Xiao},
  date = {2021},
  journaltitle = {Journal of the Physical Society of Japan},
  shortjournal = {J. Phys. Soc. Jpn.},
  volume = {90},
  number = {3},
  pages = {032001},
  issn = {0031-9015, 1347-4073},
  doi = {10.7566/JPSJ.90.032001},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/D39N7J9G/Endo et al. - 2021 - Hybrid Quantum-Classical Algorithms and Quantum Er.pdf}
}

@unpublished{farhi2018,
  title = {Classification with {{Quantum Neural Networks}} on {{Near Term Processors}}},
  author = {Farhi, Edward and Neven, Hartmut},
  date = {2018},
  eprint = {1802.06002},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1802.06002},
  abstract = {We introduce a quantum neural network, QNN, that can represent labeled data, classical or quantum, and be trained by supervised learning. The quantum circuit consists of a sequence of parameter dependent unitary transformations which acts on an input quantum state. For binary classification a single Pauli operator is measured on a designated readout qubit. The measured output is the quantum neural network's predictor of the binary label of the input state. First we look at classifying classical data sets which consist of n-bit strings with binary labels. The input quantum state is an n-bit computational basis state corresponding to a sample string. We show how to design a circuit made from two qubit unitaries that can correctly represent the label of any Boolean function of n bits. For certain label functions the circuit is exponentially long. We introduce parameter dependent unitaries that can be adapted by supervised learning of labeled data. We study an example of real world data consisting of downsampled images of handwritten digits each of which has been labeled as one of two distinct digits. We show through classical simulation that parameters can be found that allow the QNN to learn to correctly distinguish the two data sets. We then discuss presenting the data as quantum superpositions of computational basis states corresponding to different label values. Here we show through simulation that learning is possible. We consider using our QNN to learn the label of a general quantum state. By example we show that this can be done. Our work is exploratory and relies on the classical simulation of small quantum systems. The QNN proposed here was designed with near-term quantum processors in mind. Therefore it will be possible to run this QNN on a near term gate model quantum computer where its power can be explored beyond what can be explored with simulation.},
  version = {2},
  keywords = {FOS: Physical sciences,Quantum Physics (quant-ph)}
}

@article{felser2021,
  title = {Quantum-Inspired Machine Learning on High-Energy Physics Data},
  author = {Felser, Timo and Trenti, Marco and Sestini, Lorenzo and Gianelle, Alessio and Zuliani, Davide and Lucchesi, Donatella and Montangero, Simone},
  date = {2021},
  journaltitle = {npj Quantum Information},
  shortjournal = {npj Quantum Inf},
  volume = {7},
  number = {1},
  pages = {111},
  issn = {2056-6387},
  doi = {10.1038/s41534-021-00443-w},
  abstract = {Abstract             Tensor Networks, a numerical tool originally designed for simulating quantum many-body systems, have recently been applied to solve Machine Learning problems. Exploiting a tree tensor network, we apply a quantum-inspired machine learning technique to a very important and challenging big data problem in high-energy physics: the analysis and classification of data produced by the Large Hadron Collider at CERN. In particular, we present how to effectively classify so-called b-jets, jets originating from b-quarks from proton–proton collisions in the LHCb experiment, and how to interpret the classification results. We exploit the Tensor Network approach to select important features and adapt the network geometry based on information acquired in the learning process. Finally, we show how to adapt the tree tensor network to achieve optimal precision or fast response in time without the need of repeating the learning process. These results pave the way to the implementation of high-frequency real-time applications, a key ingredient needed among others for current and future LHCb event classification able to trigger events at the tens of MHz scale.},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/WAHFEIJ9/Felser et al. - 2021 - Quantum-inspired machine learning on high-energy p.pdf}
}

@article{feynman1982,
  title = {Simulating Physics with Computers},
  author = {Feynman, Richard P.},
  date = {1982},
  journaltitle = {International Journal of Theoretical Physics},
  shortjournal = {Int J Theor Phys},
  volume = {21},
  number = {6-7},
  pages = {467--488},
  issn = {0020-7748, 1572-9575},
  doi = {10.1007/BF02650179},
  langid = {english}
}

@article{fisher1936,
  title = {The {{Use}} of {{Multiple Measurements}} in {{Taxonomic Problems}}},
  author = {Fisher, Ronald A.},
  date = {1936},
  journaltitle = {Annals of Eugenics},
  volume = {7},
  number = {2},
  pages = {179--188},
  issn = {2050-1439},
  doi = {10.1111/j.1469-1809.1936.tb02137.x},
  abstract = {The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/79Q7AGVQ/Fisher - 1936 - The Use of Multiple Measurements in Taxonomic Prob.pdf;/Users/boyesjo/Zotero/storage/AGJ67A54/j.1469-1809.1936.tb02137.html}
}

@inproceedings{gagliolo2010,
  title = {Algorithm {{Selection}} as a {{Bandit Problem}} with {{Unbounded Losses}}},
  booktitle = {Learning and {{Intelligent Optimization}}},
  author = {Gagliolo, Matteo and Schmidhuber, Jürgen},
  editor = {Blum, Christian and Battiti, Roberto},
  date = {2010},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {82--96},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-13800-3_7},
  abstract = {Algorithm selection is typically based on models of algorithm performance learned during a separate offline training sequence, which can be prohibitively expensive. In recent work, we adopted an online approach, in which a performance model is iteratively updated and used to guide selection on a sequence of problem instances. The resulting exploration-exploitation trade-off was represented as a bandit problem with expert advice, using an existing solver for this game, but this required the setting of an arbitrary bound on algorithm runtimes, thus invalidating the optimal regret of the solver. In this paper, we propose a simpler framework for representing algorithm selection as a bandit problem, with partial information, and an unknown bound on losses. We adapt an existing solver to this game, proving a bound on its expected regret, which holds also for the resulting algorithm selection technique. We present experiments with a set of SAT solvers on a mixed SAT-UNSAT benchmark.},
  isbn = {978-3-642-13800-3},
  langid = {english},
  keywords = {Algorithm Portfolio,Algorithm Selection,Bandit Problem,Cumulative Loss,Problem Instance},
  file = {/Users/boyesjo/Zotero/storage/A8EY33LA/Gagliolo and Schmidhuber - 2010 - Algorithm Selection as a Bandit Problem with Unbou.pdf}
}

@article{gao2018,
  title = {A Quantum Machine Learning Algorithm Based on Generative Models},
  author = {Gao, Xun and Zhang, Z.-Y. and Duan, Luming},
  date = {2018},
  journaltitle = {Science Advances},
  shortjournal = {Sci. Adv.},
  volume = {4},
  number = {12},
  pages = {eaat9004},
  issn = {2375-2548},
  doi = {10.1126/sciadv.aat9004},
  abstract = {We propose a quantum learning algorithm for a quantum generative model and prove its advantages compared with classical models.           ,              Quantum computing and artificial intelligence, combined together, may revolutionize future technologies. A significant school of thought regarding artificial intelligence is based on generative models. Here, we propose a general quantum algorithm for machine learning based on a quantum generative model. We prove that our proposed model is more capable of representing probability distributions compared with classical generative models and has exponential speedup in learning and inference at least for some instances if a quantum computer cannot be efficiently simulated classically. Our result opens a new direction for quantum machine learning and offers a remarkable example where a quantum algorithm shows exponential improvement over classical algorithms in an important application field.},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/KMPIKHUH/Gao et al. - 2018 - A quantum machine learning algorithm based on gene.pdf}
}

@online{garcia2022,
  title = {Systematic {{Literature Review}}: {{Quantum Machine Learning}} and Its Applications},
  shorttitle = {Systematic {{Literature Review}}},
  author = {García, David Peral and Cruz-Benito, Juan and García-Peñalvo, Francisco José},
  date = {2022},
  number = {arXiv:2201.04093},
  eprint = {arXiv:2201.04093},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2201.04093},
  abstract = {Quantum computing is the process of performing calculations using quantum mechanics. This field studies the quantum behavior of certain subatomic particles for subsequent use in performing calculations, as well as for large-scale information processing. These capabilities can give quantum computers an advantage in terms of computational time and cost over classical computers. Nowadays, there are scientific challenges that are impossible to perform by classical computation due to computational complexity or the time the calculation would take, and quantum computation is one of the possible answers. However, current quantum devices have not yet the necessary qubits and are not fault-tolerant enough to achieve these goals. Nonetheless, there are other fields like machine learning or chemistry where quantum computation could be useful with current quantum devices. This manuscript aims to present a Systematic Literature Review of the papers published between 2017 and 2021 to identify, analyze and classify the different algorithms used in quantum machine learning and their applications. Consequently, this study identified 52 articles that used quantum machine learning techniques and algorithms. The main types of found algorithms are quantum implementations of classical machine learning algorithms, such as support vector machines or the k-nearest neighbor model, and classical deep learning algorithms, like quantum neural networks. Many articles try to solve problems currently answered by classical machine learning but using quantum devices and algorithms. Even though results are promising, quantum machine learning is far from achieving its full potential. An improvement in the quantum hardware is required since the existing quantum computers lack enough quality, speed, and scale to allow quantum computing to achieve its full potential.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Quantum Physics},
  file = {/Users/boyesjo/Zotero/storage/PZX7NGVY/García et al. - 2022 - Systematic Literature Review Quantum Machine Lear.pdf;/Users/boyesjo/Zotero/storage/3SD5ND8R/2201.html}
}

@article{gidney2021,
  title = {How to Factor 2048 Bit {{RSA}} Integers in 8 Hours Using 20 Million Noisy Qubits},
  author = {Gidney, Craig and Ekerå, Martin},
  date = {2021},
  journaltitle = {Quantum},
  shortjournal = {Quantum},
  volume = {5},
  pages = {433},
  issn = {2521-327X},
  doi = {10.22331/q-2021-04-15-433},
  abstract = {We significantly reduce the cost of factoring integers and computing discrete logarithms in finite fields on a quantum computer by combining techniques from Shor 1994, Griffiths-Niu 1996, Zalka 2006, Fowler 2012, Ekerå-Håstad 2017, Ekerå 2017, Ekerå 2018, Gidney-Fowler 2019, Gidney 2019. We estimate the approximate cost of our construction using plausible physical assumptions for large-scale superconducting qubit platforms: a planar grid of qubits with nearest-neighbor connectivity, a characteristic physical gate error rate of                                                   10                                        −                     3                                                                  , a surface code cycle time of 1 microsecond, and a reaction time of 10 microseconds. We account for factors that are normally ignored such as noise, the need to make repeated attempts, and the spacetime layout of the computation. When factoring 2048 bit RSA integers, our construction's spacetime volume is a hundredfold less than comparable estimates from earlier works (Van Meter et al. 2009, Jones et al. 2010, Fowler et al. 2012, Gheorghiu et al. 2019). In the abstract circuit model (which ignores overheads from distillation, routing, and error correction) our construction uses                                3                 n                 +                 0.002                 n                 lg                 ⁡                 n                              logical qubits,                                0.3                                    n                   3                                  +                 0.0005                                    n                   3                                  lg                 ⁡                 n                              Toffolis, and                                500                                    n                   2                                  +                                    n                   2                                  lg                 ⁡                 n                              measurement depth to factor                                n                              -bit RSA integers. We quantify the cryptographic implications of our work, both for RSA and for schemes based on the DLP in finite fields.},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/G8T5N3NJ/Gidney and Ekerå - 2021 - How to factor 2048 bit RSA integers in 8 hours usi.pdf}
}

@article{grinko2021,
  title = {Iterative {{Quantum Amplitude Estimation}}},
  author = {Grinko, Dmitry and Gacon, Julien and Zoufal, Christa and Woerner, Stefan},
  date = {2021},
  journaltitle = {npj Quantum Information},
  shortjournal = {npj Quantum Inf},
  volume = {7},
  number = {1},
  eprint = {1912.05559},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  pages = {52},
  issn = {2056-6387},
  doi = {10.1038/s41534-021-00379-1},
  abstract = {We introduce a new variant of Quantum Amplitude Estimation (QAE), called Iterative QAE (IQAE), which does not rely on Quantum Phase Estimation (QPE) but is only based on Grover's Algorithm, which reduces the required number of qubits and gates. We provide a rigorous analysis of IQAE and prove that it achieves a quadratic speedup up to a double-logarithmic factor compared to classical Monte Carlo simulation. Furthermore, we show with an empirical study that our algorithm outperforms other known QAE variants without QPE, some even by orders of magnitude, i.e., our algorithm requires significantly fewer samples to achieve the same estimation accuracy and confidence level.},
  keywords = {Quantum Physics},
  file = {/Users/boyesjo/Zotero/storage/296GIZK8/Grinko et al. - 2021 - Iterative Quantum Amplitude Estimation.pdf;/Users/boyesjo/Zotero/storage/BEX44CPG/1912.html}
}

@inproceedings{grover1996,
  title = {A Fast Quantum Mechanical Algorithm for Database Search},
  booktitle = {Proceedings of the Twenty-Eighth Annual {{ACM}} Symposium on {{Theory}} of {{Computing}}},
  author = {Grover, Lov K.},
  date = {1996},
  pages = {212--219},
  publisher = {{ACM Press}},
  location = {{Philadelphia, Pennsylvania, United States of America}},
  doi = {10.1145/237814.237866},
  isbn = {978-0-89791-785-8},
  langid = {english}
}

@book{gubernatis2016,
  title = {Quantum {{Monte Carlo}} Methods: Algorithms for Lattice Models},
  shorttitle = {Quantum {{Monte Carlo}} Methods},
  author = {Gubernatis, J. E. and Kawashima, N. and Werner, P.},
  date = {2016},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  isbn = {978-1-107-00642-3},
  pagetotal = {488},
  keywords = {Many-body problem,Monte Carlo method}
}

@article{gym,
  title = {{{OpenAI Gym}}},
  author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  date = {2016},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1606.01540},
  abstract = {OpenAI Gym is a toolkit for reinforcement learning research. It includes a growing collection of benchmark problems that expose a common interface, and a website where people can share their results and compare the performance of algorithms. This whitepaper discusses the components of OpenAI Gym and the design decisions that went into the software.},
  version = {1},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG)}
}

@online{hafner2023,
  title = {Mastering {{Diverse Domains}} through {{World Models}}},
  author = {Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  date = {2023},
  number = {arXiv:2301.04104},
  eprint = {arXiv:2301.04104},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2301.04104},
  abstract = {General intelligence requires solving tasks across many domains. Current reinforcement learning algorithms carry this potential but are held back by the resources and knowledge required to tune them for new tasks. We present DreamerV3, a general and scalable algorithm based on world models that outperforms previous approaches across a wide range of domains with fixed hyperparameters. These domains include continuous and discrete actions, visual and low-dimensional inputs, 2D and 3D worlds, different data budgets, reward frequencies, and reward scales. We observe favorable scaling properties of DreamerV3, with larger models directly translating to higher data-efficiency and final performance. Applied out of the box, DreamerV3 is the first algorithm to collect diamonds in Minecraft from scratch without human data or curricula, a long-standing challenge in artificial intelligence. Our general algorithm makes reinforcement learning broadly applicable and allows scaling to hard decision-making problems.},
  pubstate = {preprint},
  version = {1},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/boyesjo/Zotero/storage/AVUI4DYV/Hafner et al. - 2023 - Mastering Diverse Domains through World Models.pdf;/Users/boyesjo/Zotero/storage/UQJXLI7G/2301.html}
}

@article{hamann2022,
  title = {Performance Analysis of a Hybrid Agent for Quantum-Accessible Reinforcement Learning},
  author = {Hamann, Arne and Wölk, Sabine},
  date = {2022},
  journaltitle = {New Journal of Physics},
  shortjournal = {New J. Phys.},
  volume = {24},
  number = {3},
  pages = {033044},
  issn = {1367-2630},
  doi = {10.1088/1367-2630/ac5b56},
  abstract = {Abstract                            In the last decade quantum machine learning has provided fascinating and fundamental improvements to supervised, unsupervised and reinforcement learning (RL). In RL, a so-called agent is challenged to solve a task given by some environment. The agent learns to solve the task by exploring the environment and exploiting the rewards it gets from the environment. For some classical task environments, an analogue quantum environment can be constructed which allows to find rewards quadratically faster by applying quantum algorithms. In this paper, we analytically analyze the behavior of a hybrid agent which combines this quadratic speedup in exploration with the policy update of a classical agent. This leads to a faster learning of the hybrid agent compared to the classical agent. We demonstrate that if the classical agent needs on average ⟨               J               ⟩ rewards and ⟨               T               ⟩               cl               epochs to learn how to solve the task, the hybrid agent will take                                                                                                                                                                             ⟨                                                    T                                                  ⟩                                                                                        q                                                           ⩽                                                               α                                                                 s                                                                                                       α                                                                 o                                                                                                                                                                                        ⟨                                                            T                                                          ⟩                                                                                                        c                           l                                                                                                ⟨                                                    J                                                  ⟩                                                                                                                               epochs on average. Here,               α                                s                              and               α                                o                              denote constants depending on details of the quantum search and are independent of the problem size. Additionally, we prove that if the environment allows for maximally               α                                o                              k               max               sequential coherent interactions, e.g. due to noise effects, an improvement given by ⟨               T               ⟩               q               ≈               α                                o                              ⟨               T               ⟩               cl               /(4               k               max               ) is still possible.},
  file = {/Users/boyesjo/Zotero/storage/UW3BCAWN/Hamann and Wölk - 2022 - Performance analysis of a hybrid agent for quantum.pdf}
}

@article{havlicek2019,
  title = {Supervised Learning with Quantum Enhanced Feature Spaces},
  author = {Havlicek, Vojtech and Córcoles, Antonio D. and Temme, Kristan and Harrow, Aram W. and Kandala, Abhinav and Chow, Jerry M. and Gambetta, Jay M.},
  date = {2019},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {567},
  number = {7747},
  eprint = {1804.11326},
  eprinttype = {arxiv},
  eprintclass = {quant-ph, stat},
  pages = {209--212},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-019-0980-2},
  abstract = {Machine learning and quantum computing are two technologies each with the potential for altering how computation is performed to address previously untenable problems. Kernel methods for machine learning are ubiquitous for pattern recognition, with support vector machines (SVMs) being the most well-known method for classification problems. However, there are limitations to the successful solution to such problems when the feature space becomes large, and the kernel functions become computationally expensive to estimate. A core element to computational speed-ups afforded by quantum algorithms is the exploitation of an exponentially large quantum state space through controllable entanglement and interference. Here, we propose and experimentally implement two novel methods on a superconducting processor. Both methods represent the feature space of a classification problem by a quantum state, taking advantage of the large dimensionality of quantum Hilbert space to obtain an enhanced solution. One method, the quantum variational classifier builds on [1,2] and operates through using a variational quantum circuit to classify a training set in direct analogy to conventional SVMs. In the second, a quantum kernel estimator, we estimate the kernel function and optimize the classifier directly. The two methods present a new class of tools for exploring the applications of noisy intermediate scale quantum computers [3] to machine learning.},
  keywords = {Quantum Physics,Statistics - Machine Learning},
  file = {/Users/boyesjo/Zotero/storage/QNRJLC95/Havlicek et al. - 2019 - Supervised learning with quantum enhanced feature .pdf;/Users/boyesjo/Zotero/storage/6YXYQYCJ/1804.html}
}

@article{henderson2020,
  title = {Quanvolutional Neural Networks: Powering Image Recognition with Quantum Circuits},
  shorttitle = {Quanvolutional Neural Networks},
  author = {Henderson, Maxwell and Shakya, Samriddhi and Pradhan, Shashindra and Cook, Tristan},
  date = {2020},
  journaltitle = {Quantum Machine Intelligence},
  shortjournal = {Quantum Mach. Intell.},
  volume = {2},
  number = {1},
  pages = {2},
  issn = {2524-4906, 2524-4914},
  doi = {10.1007/s42484-020-00012-y},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/3JF9YZW4/Henderson et al. - 2020 - Quanvolutional neural networks powering image rec.pdf}
}

@inproceedings{hill2017,
  title = {An {{Efficient Bandit Algorithm}} for {{Realtime Multivariate Optimization}}},
  booktitle = {Proceedings of the 23rd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Hill, Daniel N. and Nassif, Houssam and Liu, Yi and Iyer, Anand and Vishwanathan, S.V.N.},
  date = {2017},
  pages = {1813--1821},
  publisher = {{ACM}},
  location = {{Halifax NS Canada}},
  doi = {10.1145/3097983.3098184},
  abstract = {Optimization is commonly employed to determine the content of web pages, such as to maximize conversions on landing pages or click-through rates on search engine result pages. Often the layout of these pages can be decoupled into several separate decisions. For example, the composition of a landing page may involve deciding which image to show, which wording to use, what color background to display, etc. Such optimization is a combinatorial problem over an exponentially large decision space. Randomized experiments do not scale well to this setting, and therefore, in practice, one is typically limited to optimizing a single aspect of a web page at a time. This represents a missed opportunity in both the speed of experimentation and the exploitation of possible interactions between layout decisions.},
  eventtitle = {{{KDD}} '17: {{The}} 23rd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  isbn = {978-1-4503-4887-4},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/PTPPDQ8P/Hill et al. - 2017 - An Efficient Bandit Algorithm for Realtime Multiva.pdf}
}

@inproceedings{honda2014,
  title = {Optimality of {{Thompson Sampling}} for {{Gaussian Bandits Depends}} on {{Priors}}},
  booktitle = {Proceedings of the {{Seventeenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Honda, Junya and Takemura, Akimichi},
  date = {2014},
  volume = {33},
  eprint = {1311.1894},
  eprinttype = {arxiv},
  eprintclass = {math, stat},
  pages = {375--383},
  publisher = {{PMLR}},
  location = {{Reykjavik, Iceland\vphantom\{\}}},
  url = {http://proceedings.mlr.press/v33/honda14.pdf},
  abstract = {In stochastic bandit problems, a Bayesian policy called Thompson sampling (TS) has recently attracted much attention for its excellent empirical performance. However, the theoretical analysis of this policy is difficult and its asymptotic optimality is only proved for one-parameter models. In this paper we discuss the optimality of TS for the model of normal distributions with unknown means and variances as one of the most fundamental example of multiparameter models. First we prove that the expected regret of TS with the uniform prior achieves the theoretical bound, which is the first result to show that the asymptotic bound is achievable for the normal distribution model. Next we prove that TS with Jeffreys prior and reference prior cannot achieve the theoretical bound. Therefore the choice of priors is important for TS and non-informative priors are sometimes risky in cases of multiparameter models.},
  keywords = {Mathematics - Probability,Mathematics - Statistics Theory},
  file = {/Users/boyesjo/Zotero/storage/C3NQD9DN/Honda and Takemura - 2013 - Optimality of Thompson Sampling for Gaussian Bandi.pdf;/Users/boyesjo/Zotero/storage/NWAACKE9/1311.html}
}

@article{hu2019,
  title = {Training a {{Quantum Neural Network}} to {{Solve}} the {{Contextual Multi-Armed Bandit Problem}}},
  author = {Hu, Wei and Hu, James},
  date = {2019},
  journaltitle = {Natural Science},
  shortjournal = {NS},
  volume = {11},
  number = {01},
  pages = {17--27},
  issn = {2150-4091, 2150-4105},
  doi = {10.4236/ns.2019.111003},
  file = {/Users/boyesjo/Zotero/storage/RLCTTTDG/Hu and Hu - 2019 - Training a Quantum Neural Network to Solve the Con.pdf}
}

@article{huang2021,
  title = {Experimental {{Quantum Generative Adversarial Networks}} for {{Image Generation}}},
  author = {Huang, He-Liang and Du, Yuxuan and Gong, Ming and Zhao, Youwei and Wu, Yulin and Wang, Chaoyue and Li, Shaowei and Liang, Futian and Lin, Jin and Xu, Yu and Yang, Rui and Liu, Tongliang and Hsieh, Min-Hsiu and Deng, Hui and Rong, Hao and Peng, Cheng-Zhi and Lu, Chao-Yang and Chen, Yu-Ao and Tao, Dacheng and Zhu, Xiaobo and Pan, Jian-Wei},
  date = {2021},
  journaltitle = {Physical Review Applied},
  shortjournal = {Phys. Rev. Applied},
  volume = {16},
  number = {2},
  pages = {024051},
  issn = {2331-7019},
  doi = {10.1103/PhysRevApplied.16.024051},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/9HPSWZV9/Huang et al. - 2021 - Experimental Quantum Generative Adversarial Networ.pdf}
}

@article{huang2021a,
  title = {Power of Data in Quantum Machine Learning},
  author = {Huang, Hsin-Yuan and Broughton, Michael and Mohseni, Masoud and Babbush, Ryan and Boixo, Sergio and Neven, Hartmut and McClean, Jarrod R.},
  date = {2021},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {2631},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-22539-9},
  abstract = {The use of quantum computing for machine learning is among the most exciting prospective applications of quantum technologies. However, machine learning tasks where data is provided can be considerably different than commonly studied computational tasks. In this work, we show that some problems that are classically hard to compute can be easily predicted by classical machines learning from data. Using rigorous prediction error bounds as a foundation, we develop a methodology for assessing potential quantum advantage in learning tasks. The bounds are tight asymptotically and empirically predictive for a wide range of learning models. These constructions explain numerical results showing that with the help of data, classical machine learning models can be competitive with quantum models even if they are tailored to quantum problems. We then propose a projected quantum model that provides a simple and rigorous quantum speed-up for a learning problem in the fault-tolerant regime. For near-term implementations, we demonstrate a significant prediction advantage over some classical models on engineered data sets designed to demonstrate a maximal quantum advantage in one of the largest numerical tests for gate-based quantum machine learning to date, up to 30 qubits.},
  issue = {1},
  langid = {english},
  keywords = {Computer science,Quantum information},
  file = {/Users/boyesjo/Zotero/storage/HPMR2FB7/Huang et al. - 2021 - Power of data in quantum machine learning.pdf;/Users/boyesjo/Zotero/storage/NWNE9A6U/s41467-021-22539-9.html}
}

@article{huembeli2021,
  title = {Characterizing the Loss Landscape of Variational Quantum Circuits},
  author = {Huembeli, Patrick and Dauphin, Alexandre},
  date = {2021},
  journaltitle = {Quantum Science and Technology},
  shortjournal = {Quantum Sci. Technol.},
  volume = {6},
  number = {2},
  pages = {025011},
  publisher = {{IOP Publishing}},
  issn = {2058-9565},
  doi = {10.1088/2058-9565/abdbc9},
  abstract = {Machine learning techniques enhanced by noisy intermediate-scale quantum (NISQ) devices and especially variational quantum circuits (VQC) have recently attracted much interest and have already been benchmarked for certain problems. Inspired by classical deep learning, VQCs are trained by gradient descent methods which allow for efficient training over big parameter spaces. For NISQ sized circuits, such methods show good convergence. There are however still many open questions related to the convergence of the loss function and to the trainability of these circuits in situations of vanishing gradients. Furthermore, it is not clear how ‘good’ the minima are in terms of generalization and stability against perturbations of the data and there is, therefore, a need for tools to quantitatively study the convergence of the VQCs. In this work, we introduce a way to compute the Hessian of the loss function of VQCs and show how to characterize the loss landscape with it. The eigenvalues of the Hessian give information on the local curvature and we discuss how this information can be interpreted and compared to classical neural networks. We benchmark our results on several examples, starting with a simple analytic toy model to provide some intuition about the behaviour of the Hessian, then going to bigger circuits, and also train VQCs on data. Finally, we show how the Hessian can be used to adjust the learning rate for faster convergence during the training of variational circuits.},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/5JFJ9XN6/Huembeli and Dauphin - 2021 - Characterizing the loss landscape of variational q.pdf}
}

@article{jerbi2021,
  title = {Quantum {{Enhancements}} for {{Deep Reinforcement Learning}} in {{Large Spaces}}},
  author = {Jerbi, Sofiene and Trenkwalder, Lea M. and Poulsen Nautrup, Hendrik and Briegel, Hans J. and Dunjko, Vedran},
  date = {2021},
  journaltitle = {PRX Quantum},
  shortjournal = {PRX Quantum},
  volume = {2},
  number = {1},
  pages = {010328},
  publisher = {{American Physical Society}},
  doi = {10.1103/PRXQuantum.2.010328},
  abstract = {Quantum algorithms have been successfully applied to provide computational speed ups to various machine-learning tasks and methods. A notable exception to this has been deep reinforcement learning (RL). Deep RL combines the power of deep neural networks with reinforcement learning, and has provided some of the most impressive recent artificial-intelligence (AI) results including the famous AlphaGo system—yet, no possibilities for quantum advantages have been identified to date. In this work, we show how quantum computers can enhance the performance of deep RL, especially where the action spaces are large. Specifically, we introduce so-called deep energy-based models, inspired by statistical physics, which we show outperform standard deep RL machinery in learning performance. These models are computationally more demanding, but this can be ameliorated by quantum techniques. Specifically, we provide quantum algorithms, some of which can be run on near-term quantum computers, that can be used to speed up deep energy-based RL. This result opens up a new playing field for quantum enhancements in machine learning and AI.},
  keywords = {quantum computation,reinforcement learning},
  file = {/Users/boyesjo/Zotero/storage/EFJSN3DL/Jerbi et al. - 2021 - Quantum Enhancements for Deep Reinforcement Learni.pdf;/Users/boyesjo/Zotero/storage/QI8SWY45/PRXQuantum.2.html}
}

@online{jerbi2021a,
  title = {Parametrized Quantum Policies for Reinforcement Learning},
  author = {Jerbi, Sofiene and Gyurik, Casper and Marshall, Simon C. and Briegel, Hans J. and Dunjko, Vedran},
  date = {2021},
  number = {arXiv:2103.05577},
  eprint = {arXiv:2103.05577},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2103.05577},
  abstract = {With the advent of real-world quantum computing, the idea that parametrized quantum computations can be used as hypothesis families in a quantum-classical machine learning system is gaining increasing traction. Such hybrid systems have already shown the potential to tackle real-world tasks in supervised and generative learning, and recent works have established their provable advantages in special artificial tasks. Yet, in the case of reinforcement learning, which is arguably most challenging and where learning boosts would be extremely valuable, no proposal has been successful in solving even standard benchmarking tasks, nor in showing a theoretical learning advantage over classical algorithms. In this work, we achieve both. We propose a hybrid quantum-classical reinforcement learning model using very few qubits, which we show can be effectively trained to solve several standard benchmarking environments. Moreover, we demonstrate, and formally prove, the ability of parametrized quantum circuits to solve certain learning tasks that are intractable for classical models, including current state-of-art deep neural networks, under the widely-believed classical hardness of the discrete logarithm problem.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Quantum Physics,Statistics - Machine Learning},
  file = {/Users/boyesjo/Zotero/storage/IECLRNWT/Jerbi et al. - 2021 - Parametrized quantum policies for reinforcement le.pdf;/Users/boyesjo/Zotero/storage/DJGVVPPY/2103.html}
}

@article{jin2020,
  title = {{{MOTS}}: {{Minimax Optimal Thompson Sampling}}},
  shorttitle = {{{MOTS}}},
  author = {Jin, Tianyuan and Xu, Pan and Shi, Jieming and Xiao, Xiaokui and Gu, Quanquan},
  date = {2020},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2003.01803},
  abstract = {Thompson sampling is one of the most widely used algorithms for many online decision problems, due to its simplicity in implementation and superior empirical performance over other state-of-the-art methods. Despite its popularity and empirical success, it has remained an open problem whether Thompson sampling can match the minimax lower bound \$Ω(\textbackslash sqrt\{KT\})\$ for \$K\$-armed bandit problems, where \$T\$ is the total time horizon. In this paper, we solve this long open problem by proposing a variant of Thompson sampling called MOTS that adaptively clips the sampling instance of the chosen arm at each time step. We prove that this simple variant of Thompson sampling achieves the minimax optimal regret bound \$O(\textbackslash sqrt\{KT\})\$ for finite time horizon \$T\$, as well as the asymptotic optimal regret bound for Gaussian rewards when \$T\$ approaches infinity. To our knowledge, MOTS is the first Thompson sampling type algorithm that achieves the minimax optimality for multi-armed bandit problems.},
  version = {3},
  keywords = {FOS: Computer and information sciences,FOS: Mathematics,Machine Learning (cs.LG),Machine Learning (stat.ML),Statistics Theory (math.ST)}
}

@incollection{kaufmann2012,
  title = {Thompson {{Sampling}}: {{An Asymptotically Optimal Finite-Time Analysis}}},
  shorttitle = {Thompson {{Sampling}}},
  booktitle = {Algorithmic {{Learning Theory}}},
  author = {Kaufmann, Emilie and Korda, Nathaniel and Munos, Rémi},
  editor = {Bshouty, Nader H. and Stoltz, Gilles and Vayatis, Nicolas and Zeugmann, Thomas},
  date = {2012},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {7568},
  pages = {199--213},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-34106-9_18},
  editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
  editorbtype = {redactor},
  isbn = {978-3-642-34105-2 978-3-642-34106-9},
  file = {/Users/boyesjo/Zotero/storage/YKETXUZY/Kaufmann et al. - 2012 - Thompson Sampling An Asymptotically Optimal Finit.pdf}
}

@unpublished{kawale2018,
  title = {A {{Multi-Armed Bandit Framework}} for {{Recommendations}} at {{Netflix}}},
  author = {Kawale, Jaya and Chow, Elliot},
  date = {2018},
  url = {https://www.datacouncil.ai/talks/a-multi-armed-bandit-framework-for-recommendations-at-netflix},
  eventtitle = {Data {{Council}}}
}

@article{killoran2019,
  title = {Continuous-Variable Quantum Neural Networks},
  author = {Killoran, Nathan and Bromley, Thomas R. and Arrazola, Juan Miguel and Schuld, Maria and Quesada, Nicolás and Lloyd, Seth},
  date = {2019},
  journaltitle = {Physical Review Research},
  shortjournal = {Phys. Rev. Research},
  volume = {1},
  number = {3},
  pages = {033063},
  issn = {2643-1564},
  doi = {10.1103/PhysRevResearch.1.033063},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/ZKTXC3FF/Killoran et al. - 2019 - Continuous-variable quantum neural networks.pdf}
}

@article{kuleshov2014a,
  title = {Algorithms for Multi-Armed Bandit Problems},
  author = {Kuleshov, Volodymyr and Precup, Doina},
  date = {2014},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1402.6028},
  abstract = {Although many algorithms for the multi-armed bandit problem are well-understood theoretically, empirical confirmation of their effectiveness is generally scarce. This paper presents a thorough empirical study of the most popular multi-armed bandit algorithms. Three important observations can be made from our results. Firstly, simple heuristics such as epsilon-greedy and Boltzmann exploration outperform theoretically sound algorithms on most settings by a significant margin. Secondly, the performance of most algorithms varies dramatically with the parameters of the bandit problem. Our study identifies for each algorithm the settings where it performs well, and the settings where it performs poorly. Thirdly, the algorithms' performance relative each to other is affected only by the number of bandit arms and the variance of the rewards. This finding may guide the design of subsequent empirical evaluations. In the second part of the paper, we turn our attention to an important area of application of bandit algorithms: clinical trials. Although the design of clinical trials has been one of the principal practical problems motivating research on multi-armed bandits, bandit algorithms have never been evaluated as potential treatment allocation strategies. Using data from a real study, we simulate the outcome that a 2001-2002 clinical trial would have had if bandit algorithms had been used to allocate patients to treatments. We find that an adaptive trial would have successfully treated at least 50\% more patients, while significantly reducing the number of adverse effects and increasing patient retention. At the end of the trial, the best treatment could have still been identified with a high level of statistical confidence. Our findings demonstrate that bandit algorithms are attractive alternatives to current adaptive treatment allocation strategies.},
  version = {1},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG)},
  file = {/Users/boyesjo/Zotero/storage/AT5JN7BD/1402.6028-2.pdf}
}

@inproceedings{kwak2021,
  title = {Introduction to {{Quantum Reinforcement Learning}}: {{Theory}} and {{PennyLane-based Implementation}}},
  shorttitle = {Introduction to {{Quantum Reinforcement Learning}}},
  booktitle = {2021 {{International Conference}} on {{Information}} and {{Communication Technology Convergence}} ({{ICTC}})},
  author = {Kwak, Yunseok and Yun, Won Joon and Jung, Soyi and Kim, Jong-Kook and Kim, Joongheon},
  date = {2021},
  pages = {416--420},
  issn = {2162-1233},
  doi = {10.1109/ICTC52510.2021.9620885},
  abstract = {The emergence of quantum computing enables for researchers to apply quantum circuit on many existing studies. Utilizing quantum circuit and quantum differential programming, many research are conducted such as Quantum Machine Learning (QML). In particular, quantum reinforcement learning is a good field to test the possibility of quantum machine learning, and a lot of research is being done. This work will introduce the concept of quantum reinforcement learning using a variational quantum circuit, and confirm its possibility through implementation and experimentation. We will first present the background knowledge and working principle of quantum reinforcement learning, and then guide the implementation method using the PennyLane library. We will also discuss the power and possibility of quantum reinforcement learning from the experimental results obtained through this work.},
  eventtitle = {2021 {{International Conference}} on {{Information}} and {{Communication Technology Convergence}} ({{ICTC}})},
  keywords = {Convergence,Information and communication technology,Libraries,Programming,Quantum circuit,quantum computation,Quantum mechanics,Reinforcement learning},
  file = {/Users/boyesjo/Zotero/storage/BMDH4PJP/Kwak et al. - 2021 - Introduction to Quantum Reinforcement Learning Th.pdf;/Users/boyesjo/Zotero/storage/N3RBZSTY/9620885.html}
}

@inproceedings{kwak2021a,
  title = {Quantum {{Neural Networks}}: {{Concepts}}, {{Applications}}, and {{Challenges}}},
  shorttitle = {Quantum {{Neural Networks}}},
  booktitle = {Twelfth {{International Conference}} on {{Ubiquitous}} and {{Future Networks}} ({{ICUFN}})},
  author = {Kwak, Yunseok and Yun, Won Joon and Jung, Soyi and Kim, Joongheon},
  date = {2021},
  pages = {413--416},
  publisher = {{IEEE}},
  location = {{Jeju Island, Republic of Korea}},
  doi = {10.1109/ICUFN49451.2021.9528698},
  isbn = {978-1-72816-476-2},
  file = {/Users/boyesjo/Zotero/storage/GSNV2YYF/Kwak et al. - 2021 - Quantum Neural Networks Concepts, Applications, a.pdf}
}

@article{lai1985,
  title = {Asymptotically Efficient Adaptive Allocation Rules},
  author = {Lai, T.L and Robbins, Herbert},
  date = {1985},
  journaltitle = {Advances in Applied Mathematics},
  shortjournal = {Advances in Applied Mathematics},
  volume = {6},
  number = {1},
  pages = {4--22},
  issn = {01968858},
  doi = {10.1016/0196-8858(85)90002-8},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/VNIZ488S/Lai and Robbins - 1985 - Asymptotically efficient adaptive allocation rules.pdf}
}

@online{lan2021,
  title = {Variational {{Quantum Soft Actor-Critic}}},
  author = {Lan, Qingfeng},
  date = {2021},
  number = {arXiv:2112.11921},
  eprint = {arXiv:2112.11921},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2112.11921},
  abstract = {Quantum computing has a superior advantage in tackling specific problems, such as integer factorization and Simon's problem. For more general tasks in machine learning, by applying variational quantum circuits, more and more quantum algorithms have been proposed recently, especially in supervised learning and unsupervised learning. However, little work has been done in reinforcement learning, arguably more important and challenging. Previous work in quantum reinforcement learning mainly focuses on discrete control tasks where the action space is discrete. In this work, we develop a quantum reinforcement learning algorithm based on soft actor-critic -- one of the state-of-the-art methods for continuous control. Specifically, we use a hybrid quantum-classical policy network consisting of a variational quantum circuit and a classical artificial neural network. Tested in a standard reinforcement learning benchmark, we show that this quantum version of soft actor-critic is comparable with the original soft actor-critic, using much less adjustable parameters. Furthermore, we analyze the effect of different hyper-parameters and policy network architectures, pointing out the importance of architecture design for quantum reinforcement learning.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Quantum Physics},
  file = {/Users/boyesjo/Zotero/storage/4723LUQL/Lan - 2021 - Variational Quantum Soft Actor-Critic.pdf;/Users/boyesjo/Zotero/storage/VQ77UCTH/2112.html}
}

@online{laskin2022,
  title = {In-Context {{Reinforcement Learning}} with {{Algorithm Distillation}}},
  author = {Laskin, Michael and Wang, Luyu and Oh, Junhyuk and Parisotto, Emilio and Spencer, Stephen and Steigerwald, Richie and Strouse, D. J. and Hansen, Steven and Filos, Angelos and Brooks, Ethan and Gazeau, Maxime and Sahni, Himanshu and Singh, Satinder and Mnih, Volodymyr},
  date = {2022},
  number = {arXiv:2210.14215},
  eprint = {arXiv:2210.14215},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2210.14215},
  abstract = {We propose Algorithm Distillation (AD), a method for distilling reinforcement learning (RL) algorithms into neural networks by modeling their training histories with a causal sequence model. Algorithm Distillation treats learning to reinforcement learn as an across-episode sequential prediction problem. A dataset of learning histories is generated by a source RL algorithm, and then a causal transformer is trained by autoregressively predicting actions given their preceding learning histories as context. Unlike sequential policy prediction architectures that distill post-learning or expert sequences, AD is able to improve its policy entirely in-context without updating its network parameters. We demonstrate that AD can reinforcement learn in-context in a variety of environments with sparse rewards, combinatorial task structure, and pixel-based observations, and find that AD learns a more data-efficient RL algorithm than the one that generated the source data.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,reinforcement learning},
  file = {/Users/boyesjo/Zotero/storage/I5P6XDGQ/Laskin et al. - 2022 - In-context Reinforcement Learning with Algorithm D.pdf}
}

@book{lattimore2020,
  title = {Bandit {{Algorithms}}},
  author = {Lattimore, Tor and Szepesvári, Csaba},
  date = {2020},
  edition = {1},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781108571401},
  isbn = {978-1-108-57140-1 978-1-108-48682-8},
  keywords = {Bandits},
  file = {/Users/boyesjo/Zotero/storage/YM3H6BTI/Lattimore and Szepesvári - 2020 - Bandit Algorithms.pdf}
}

@inproceedings{lattimore2021,
  title = {Bandit {{Phase Retrieval}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lattimore, Tor and Hao, Botao},
  date = {2021},
  volume = {34},
  pages = {18801--18811},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2021/hash/9c36b930df0e0e8b05d4e1fcb4cdef27-Abstract.html},
  keywords = {Bandits,Meta},
  file = {/Users/boyesjo/Zotero/storage/DBA7MAN7/Lattimore and Hao - 2021 - Bandit Phase Retrieval.pdf}
}

@article{liu2018,
  title = {Quantum Machine Learning for Quantum Anomaly Detection},
  author = {Liu, Nana and Rebentrost, Patrick},
  date = {2018},
  journaltitle = {Physical Review A},
  shortjournal = {Phys. Rev. A},
  volume = {97},
  number = {4},
  eprint = {1710.07405},
  eprinttype = {arxiv},
  pages = {042315},
  issn = {2469-9926, 2469-9934},
  doi = {10.1103/PhysRevA.97.042315},
  abstract = {Anomaly detection is used for identifying data that deviate from `normal' data patterns. Its usage on classical data finds diverse applications in many important areas like fraud detection, medical diagnoses, data cleaning and surveillance. With the advent of quantum technologies, anomaly detection of quantum data, in the form of quantum states, may become an important component of quantum applications. Machine learning algorithms are playing pivotal roles in anomaly detection using classical data. Two widely-used algorithms are kernel principal component analysis and one-class support vector machine. We find corresponding quantum algorithms to detect anomalies in quantum states. We show that these two quantum algorithms can be performed using resources logarithmic in the dimensionality of quantum states. For pure quantum states, these resources can also be logarithmic in the number of quantum states used for training the machine learning algorithm. This makes these algorithms potentially applicable to big quantum data applications.},
  keywords = {Quantum Physics},
  file = {/Users/boyesjo/Zotero/storage/WS4AI3BZ/Liu and Rebentrost - 2018 - Quantum machine learning for quantum anomaly detec.pdf;/Users/boyesjo/Zotero/storage/5V6299LN/1710.html}
}

@article{liu2021,
  title = {A Rigorous and Robust Quantum Speed-up in Supervised Machine Learning},
  author = {Liu, Yunchao and Arunachalam, Srinivasan and Temme, Kristan},
  date = {2021},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {17},
  number = {9},
  pages = {1013--1017},
  issn = {1745-2473, 1745-2481},
  doi = {10.1038/s41567-021-01287-z},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/KUHSD6AF/Liu et al. - 2021 - A rigorous and robust quantum speed-up in supervis.pdf}
}

@inproceedings{liu2022,
  title = {Quantum {{Reinforcement Learning}} for {{Multi-Armed Bandits}}},
  booktitle = {2022 41st {{Chinese Control Conference}} ({{CCC}})},
  author = {Liu, Yi-Pei and Li, Kuo and Cao, Xi and Jia, Qing-Shan and Wang, Xu},
  date = {2022},
  pages = {5675--5680},
  issn = {1934-1768},
  doi = {10.23919/CCC55666.2022.9902595},
  abstract = {This work focuses on the multi-armed bandits (MAB) problem and proposes a quantum reinforcement learning (RL) algorithm for action selection. Existing quantum RL algorithms generally assume that some prior information about the optimal action is known, and initial probability is set unequally. Our algorithm can be executed with equal initial probability on each action, and can greatly accelerate the learning process.},
  eventtitle = {2022 41st {{Chinese Control Conference}} ({{CCC}})},
  keywords = {Bandits,Computational efficiency,multi-arm bandits,quantum computation,Quantum computing,reinforcement learning,Reinforcement learning},
  file = {/Users/boyesjo/Zotero/storage/DYG2WDKE/Liu et al. - 2022 - Quantum Reinforcement Learning for Multi-Armed Ban.pdf;/Users/boyesjo/Zotero/storage/D4WZWGQQ/authors.html}
}

@unpublished{lloyd2013,
  title = {Quantum Algorithms for Supervised and Unsupervised Machine Learning},
  author = {Lloyd, Seth and Mohseni, Masoud and Rebentrost, Patrick},
  date = {2013},
  eprint = {1307.0411},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  url = {http://arxiv.org/abs/1307.0411},
  abstract = {Machine-learning tasks frequently involve problems of manipulating and classifying large numbers of vectors in high-dimensional spaces. Classical algorithms for solving such problems typically take time polynomial in the number of vectors and the dimension of the space. Quantum computers are good at manipulating high-dimensional vectors in large tensor product spaces. This paper provides supervised and unsupervised quantum machine learning algorithms for cluster assignment and cluster finding. Quantum machine learning can take time logarithmic in both the number of vectors and their dimension, an exponential speed-up over classical algorithms.},
  keywords = {Quantum Physics},
  file = {/Users/boyesjo/Zotero/storage/FYVDZ6I3/Lloyd et al. - 2013 - Quantum algorithms for supervised and unsupervised.pdf;/Users/boyesjo/Zotero/storage/LFUJ6VUM/1307.html}
}

@article{lumbreras2022,
  title = {Multi-Armed Quantum Bandits: {{Exploration}} versus Exploitation When Learning Properties of Quantum States},
  shorttitle = {Multi-Armed Quantum Bandits},
  author = {Lumbreras, Josep and Haapasalo, Erkka and Tomamichel, Marco},
  date = {2022},
  journaltitle = {Quantum},
  shortjournal = {Quantum},
  volume = {6},
  pages = {749},
  issn = {2521-327X},
  doi = {10.22331/q-2022-06-29-749},
  abstract = {We initiate the study of tradeoffs between exploration and exploitation in online learning of properties of quantum states. Given sequential oracle access to an unknown quantum state, in each round, we are tasked to choose an observable from a set of actions aiming to maximize its expectation value on the state (the reward). Information gained about the unknown state from previous rounds can be used to gradually improve the choice of action, thus reducing the gap between the reward and the maximal reward attainable with the given action set (the regret). We provide various information-theoretic lower bounds on the cumulative regret that an optimal learner must incur, and show that it scales at least as the square root of the number of rounds played. We also investigate the dependence of the cumulative regret on the number of available actions and the dimension of the underlying space. Moreover, we exhibit strategies that are optimal for bandits with a finite number of arms and general mixed states.},
  langid = {english},
  keywords = {Bandits,quantum computation},
  file = {/Users/boyesjo/Zotero/storage/QZ7SADI9/Lumbreras et al. - 2022 - Multi-armed quantum bandits Exploration versus ex.pdf}
}

@article{madsen2022,
  title = {Quantum Computational Advantage with a Programmable Photonic Processor},
  author = {Madsen, Lars S. and Laudenbach, Fabian and Askarani, Mohsen Falamarzi and Rortais, Fabien and Vincent, Trevor and Bulmer, Jacob F. F. and Miatto, Filippo M. and Neuhaus, Leonhard and Helt, Lukas G. and Collins, Matthew J. and Lita, Adriana E. and Gerrits, Thomas and Nam, Sae Woo and Vaidya, Varun D. and Menotti, Matteo and Dhand, Ish and Vernon, Zachary and Quesada, Nicolás and Lavoie, Jonathan},
  date = {2022},
  journaltitle = {Nature},
  volume = {606},
  number = {7912},
  pages = {75--81},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-022-04725-x},
  abstract = {A quantum computer attains computational advantage when outperforming the best classical computers running the best-known algorithms on well-defined tasks. No photonic machine offering programmability over all its quantum gates has demonstrated quantum computational advantage: previous machines1,2 were largely restricted to static gate sequences. Earlier photonic demonstrations were also vulnerable to spoofing3, in which classical heuristics produce samples, without direct simulation, lying closer to the ideal distribution than do samples from the quantum hardware. Here~we report quantum computational advantage using Borealis, a photonic processor offering dynamic programmability on all gates implemented. We carry out Gaussian boson sampling4 (GBS) on 216 squeezed modes entangled with three-dimensional connectivity5, using a time-multiplexed and photon-number-resolving architecture. On average, it would take more than 9,000\,years for the best available algorithms and supercomputers to produce, using exact methods, a single sample from the programmed distribution, whereas Borealis requires only 36\,μs. This runtime advantage is over 50 million times as extreme as that reported from earlier photonic machines. Ours constitutes a very large GBS experiment, registering events with up to 219 photons and a mean photon number of 125. This work is a critical milestone on the path to a practical quantum computer, validating key technological features of photonics as a platform for this goal.},
  issue = {7912},
  langid = {english},
  keywords = {Information theory and computation,Quantum information,Quantum optics,Quantum simulation,Single photons and quantum effects},
  file = {/Users/boyesjo/Zotero/storage/CD9HBLDC/Madsen et al. - 2022 - Quantum computational advantage with a programmabl.pdf;/Users/boyesjo/Zotero/storage/ALA6B6XE/s41586-022-04725-x.html}
}

@article{maillard2011,
  title = {A {{Finite-Time Analysis}} of {{Multi-armed Bandits Problems}} with {{Kullback-Leibler Divergences}}},
  author = {Maillard, Odalric-Ambrym and Munos, Rémi and Stoltz, Gilles},
  date = {2011},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1105.5820},
  abstract = {We consider a Kullback-Leibler-based algorithm for the stochastic multi-armed bandit problem in the case of distributions with finite supports (not necessarily known beforehand), whose asymptotic regret matches the lower bound of \textbackslash cite\{Burnetas96\}. Our contribution is to provide a finite-time analysis of this algorithm; we get bounds whose main terms are smaller than the ones of previously known algorithms with finite-time analyses (like UCB-type algorithms).},
  version = {1},
  keywords = {FOS: Mathematics,Statistics Theory (math.ST)},
  file = {/Users/boyesjo/Zotero/storage/YZU2RXFG/Maillard et al. - 2011 - A Finite-Time Analysis of Multi-armed Bandits Prob.pdf}
}

@article{mcclean2018,
  title = {Barren Plateaus in Quantum Neural Network Training Landscapes},
  author = {McClean, Jarrod R. and Boixo, Sergio and Smelyanskiy, Vadim N. and Babbush, Ryan and Neven, Hartmut},
  date = {2018},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {9},
  number = {1},
  eprint = {1803.11173},
  eprinttype = {arxiv},
  pages = {4812},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-07090-4},
  abstract = {Many experimental proposals for noisy intermediate scale quantum devices involve training a parameterized quantum circuit with a classical optimization loop. Such hybrid quantum-classical algorithms are popular for applications in quantum simulation, optimization, and machine learning. Due to its simplicity and hardware efficiency, random circuits are often proposed as initial guesses for exploring the space of quantum states. We show that the exponential dimension of Hilbert space and the gradient estimation complexity make this choice unsuitable for hybrid quantum-classical algorithms run on more than a few qubits. Specifically, we show that for a wide class of reasonable parameterized quantum circuits, the probability that the gradient along any reasonable direction is non-zero to some fixed precision is exponentially small as a function of the number of qubits. We argue that this is related to the 2-design characteristic of random circuits, and that solutions to this problem must be studied.},
  keywords = {Computer Science - Machine Learning,Physics - Chemical Physics,Quantum Physics},
  file = {/Users/boyesjo/Zotero/storage/6KLFH2UD/McClean et al. - 2018 - Barren plateaus in quantum neural network training.pdf;/Users/boyesjo/Zotero/storage/2JZLUWKI/1803.html}
}

@article{menard2017,
  title = {A Minimax and Asymptotically Optimal Algorithm for Stochastic Bandits},
  author = {Ménard, Pierre and Garivier, Aurélien},
  date = {2017},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1702.07211},
  abstract = {We propose the kl-UCB ++ algorithm for regret minimization in stochastic bandit models with exponential families of distributions. We prove that it is simultaneously asymptotically optimal (in the sense of Lai and Robbins' lower bound) and minimax optimal. This is the first algorithm proved to enjoy these two properties at the same time. This work thus merges two different lines of research with simple and clear proofs.},
  version = {2},
  keywords = {FOS: Computer and information sciences,FOS: Mathematics,Machine Learning (cs.LG),Machine Learning (stat.ML),Statistics Theory (math.ST)},
  file = {/Users/boyesjo/Zotero/storage/4HDJRIL9/Ménard and Garivier - 2017 - A minimax and asymptotically optimal algorithm for.pdf}
}

@online{meyerSurveyQuantumReinforcement2022,
  title = {A {{Survey}} on {{Quantum Reinforcement Learning}}},
  author = {Meyer, Nico and Ufrecht, Christian and Periyasamy, Maniraman and Scherer, Daniel D. and Plinge, Axel and Mutschler, Christopher},
  date = {2022-11-07},
  number = {arXiv:2211.03464},
  eprint = {arXiv:2211.03464},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2211.03464},
  abstract = {Quantum reinforcement learning is an emerging field at the intersection of quantum computing and machine learning. While we intend to provide a broad overview of the literature on quantum reinforcement learning (our interpretation of this term will be clarified below), we put particular emphasis on recent developments. With a focus on already available noisy intermediate-scale quantum devices, these include variational quantum circuits acting as function approximators in an otherwise classical reinforcement learning setting. In addition, we survey quantum reinforcement learning algorithms based on future fault-tolerant hardware, some of which come with a provable quantum advantage. We provide both a birds-eye-view of the field, as well as summaries and reviews for selected parts of the literature.},
  pubstate = {preprint},
  keywords = {Quantum Physics},
  file = {/Users/boyesjo/Zotero/storage/98WZ48QR/Meyer et al. - 2022 - A Survey on Quantum Reinforcement Learning.pdf;/Users/boyesjo/Zotero/storage/JVPCDUSR/2211.html}
}

@article{moll2018,
  title = {Quantum Optimization Using Variational Algorithms on Near-Term Quantum Devices},
  author = {Moll, Nikolaj and Barkoutsos, Panagiotis and Bishop, Lev S and Chow, Jerry M and Cross, Andrew and Egger, Daniel J and Filipp, Stefan and Fuhrer, Andreas and Gambetta, Jay M and Ganzhorn, Marc and Kandala, Abhinav and Mezzacapo, Antonio and Müller, Peter and Riess, Walter and Salis, Gian and Smolin, John and Tavernelli, Ivano and Temme, Kristan},
  date = {2018},
  journaltitle = {Quantum Science and Technology},
  shortjournal = {Quantum Sci. Technol.},
  volume = {3},
  number = {3},
  pages = {030503},
  issn = {2058-9565},
  doi = {10.1088/2058-9565/aab822},
  file = {/Users/boyesjo/Zotero/storage/8N9GTHHI/Moll et al. - 2018 - Quantum optimization using variational algorithms .pdf}
}

@article{montanaro2015,
  title = {Quantum Speedup of {{Monte Carlo}} Methods},
  author = {Montanaro, Ashley},
  date = {2015},
  journaltitle = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  shortjournal = {Proc. R. Soc. A.},
  volume = {471},
  number = {2181},
  pages = {20150301},
  issn = {1364-5021, 1471-2946},
  doi = {10.1098/rspa.2015.0301},
  abstract = {Monte Carlo methods use random sampling to estimate numerical quantities which are hard to compute deterministically. One important example is the use in statistical physics of rapidly mixing Markov chains to approximately compute partition functions. In this work, we describe a quantum algorithm which can accelerate Monte Carlo methods in a very general setting. The algorithm estimates the expected output value of an arbitrary randomized or quantum subroutine with bounded variance, achieving a near-quadratic speedup over the best possible classical algorithm. Combining the algorithm with the use of quantum walks gives a quantum speedup of the fastest known classical algorithms with rigorous performance bounds for computing partition functions, which use multiple-stage Markov chain Monte Carlo techniques. The quantum algorithm can also be used to estimate the total variation distance between probability distributions efficiently.},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/UHEJQTT9/Montanaro - 2015 - Quantum speedup of Monte Carlo methods.pdf}
}

@article{nakaji2020,
  title = {Faster Amplitude Estimation},
  author = {Nakaji, Kouhei},
  date = {2020},
  journaltitle = {Quantum Information and Computation},
  shortjournal = {Quantum Information and Computation},
  volume = {20},
  pages = {1109--1123},
  doi = {10.26421/QIC20.13-14-2},
  abstract = {In this paper, we introduce an efficient algorithm for the quantum amplitude estimation task which is tailored for near-term quantum computers. The quantum amplitude estimation is an important problem which has various applications in fields such as quantum chemistry, machine learning, and finance. Because the well-known algorithm for the quantum amplitude estimation using the phase estimation does not work in near-term quantum computers, alternative approaches have been proposed in recent literature. Some of them provide a proof of the upper bound which almost achieves the Heisenberg scaling. However, the constant factor is large and thus the bound is loose. Our contribution in this paper is to provide the algorithm such that the upper bound of query complexity almost achieves the Heisenberg scaling and the constant factor is small.},
  file = {/Users/boyesjo/Zotero/storage/RFMCL38U/Nakaji - 2020 - Faster amplitude estimation.pdf}
}

@article{nakkiran2021,
  title = {Deep Double Descent: Where Bigger Models and More Data Hurt},
  shorttitle = {Deep Double Descent},
  author = {Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
  date = {2021},
  journaltitle = {Journal of Statistical Mechanics: Theory and Experiment},
  shortjournal = {J. Stat. Mech.},
  volume = {2021},
  number = {12},
  pages = {124003},
  issn = {1742-5468},
  doi = {10.1088/1742-5468/ac3a74},
  abstract = {Abstract                            We show that a variety of modern deep learning tasks exhibit a ‘double-descent’ phenomenon where, as we increase model size, performance first gets               worse               and then gets better. Moreover, we show that double descent occurs not just as a function of model size, but also as a function of the number of training epochs. We unify the above phenomena by defining a new complexity measure we call the               effective model complexity               and conjecture a generalized double descent with respect to this measure. Furthermore, our notion of model complexity allows us to identify certain regimes where increasing (even quadrupling) the number of train samples actually               hurts               test performance.},
  file = {/Users/boyesjo/Zotero/storage/C7D7WBSW/Nakkiran et al. - 2021 - Deep double descent where bigger models and more .pdf}
}

@book{nielsen2012,
  title = {Quantum {{Computation}} and {{Quantum Information}}: 10th {{Anniversary Edition}}},
  shorttitle = {Quantum {{Computation}} and {{Quantum Information}}},
  author = {Nielsen, Michael A. and Chuang, Isaac L.},
  date = {2012},
  edition = {1},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9780511976667},
  abstract = {One of the most cited books in physics of all time, Quantum Computation and Quantum Information remains the best textbook in this exciting field of science. This 10th anniversary edition includes an introduction from the authors setting the work in context. This comprehensive textbook describes such remarkable effects as fast quantum algorithms, quantum teleportation, quantum cryptography and quantum error-correction. Quantum mechanics and computer science are introduced before moving on to describe what a quantum computer is, how it can be used to solve problems faster than 'classical' computers and its real-world implementation. It concludes with an in-depth treatment of quantum information. Containing a wealth of figures and exercises, this well-known textbook is ideal for courses on the subject, and will interest beginning graduate students and researchers in physics, computer science, mathematics, and electrical engineering.},
  isbn = {978-0-511-97666-7},
  file = {/Users/boyesjo/Zotero/storage/W4ZMECV7/Nielsen and Chuang - 2012 - Quantum Computation and Quantum Information 10th .pdf}
}

@inproceedings{oh2020,
  title = {A {{Tutorial}} on {{Quantum Convolutional Neural Networks}} ({{QCNN}})},
  booktitle = {International {{Conference}} on {{Information}} and {{Communication Technology Convergence}}},
  author = {Oh, Seunghyeok and Choi, Jaeho and Kim, Joongheon},
  date = {2020},
  pages = {236--239},
  publisher = {{IEEE}},
  location = {{Jeju Island, Republic of Korea}},
  doi = {10.1109/ICTC49870.2020.9289439},
  isbn = {978-1-72816-758-9},
  file = {/Users/boyesjo/Zotero/storage/AQ2KMFBH/Oh et al. - 2020 - A Tutorial on Quantum Convolutional Neural Network.pdf}
}

@unpublished{park2020,
  title = {Practical Application Improvement to {{Quantum SVM}}: Theory to Practice},
  shorttitle = {Practical Application Improvement to {{Quantum SVM}}},
  author = {Park, Jae-Eun and Quanz, Brian and Wood, Steve and Higgins, Heather and Harishankar, Ray},
  date = {2020},
  eprint = {2012.07725},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  url = {http://arxiv.org/abs/2012.07725},
  abstract = {Quantum machine learning (QML) has emerged as an important area for Quantum applications, although useful QML applications would require many qubits. Therefore our paper is aimed at exploring the successful application of the Quantum Support Vector Machine (QSVM) algorithm while balancing several practical and technical considerations under the Noisy Intermediate-Scale Quantum (NISQ) assumption. For the quantum SVM under NISQ, we use quantum feature maps to translate data into quantum states and build the SVM kernel out of these quantum states, and further compare with classical SVM with radial basis function (RBF) kernels. As data sets are more complex or abstracted in some sense, classical SVM with classical kernels leads to less accuracy compared to QSVM, as classical SVM with typical classical kernels cannot easily separate different class data. Similarly, QSVM should be able to provide competitive performance over a broader range of data sets including ``simpler'' data cases in which smoother decision boundaries are required to avoid any model variance issues (i.e., overfitting). To bridge the gap between ``classical-looking'' decision boundaries and complex quantum decision boundaries, we propose to utilize general shallow unitary transformations to create feature maps with rotation factors to define a tunable quantum kernel, and added regularization to smooth the separating hyperplane model. We show in experiments that this allows QSVM to perform equally to SVM regardless of the complexity of the data sets and outperform in some commonly used reference data sets.},
  keywords = {Computer Science - Machine Learning,Quantum Physics}
}

@inproceedings{pavlidis2008,
  title = {Simulation {{Studies}} of {{Multi-armed Bandits}} with {{Covariates}} ({{Invited Paper}})},
  booktitle = {Tenth {{International Conference}} on {{Computer Modeling}} and {{Simulation}} (Uksim 2008)},
  author = {Pavlidis, Nicos G. and Tasoulis, Dimitris K. and Hand, David J.},
  date = {2008},
  pages = {493--498},
  publisher = {{IEEE}},
  location = {{Cambridge, UK}},
  doi = {10.1109/UKSIM.2008.86},
  eventtitle = {Tenth {{International Conference}} on {{Computer Modeling}} and {{Simulation}} (Uksim 2008)},
  isbn = {978-0-7695-3114-4},
  keywords = {Bandits,Empirical},
  file = {/Users/boyesjo/Zotero/storage/PZK7KLF8/Pavlidis et al. - 2008 - Simulation Studies of Multi-armed Bandits with Cov.pdf}
}

@online{pennylane,
  title = {{{PennyLane}}: {{Automatic}} Differentiation of Hybrid Quantum-Classical Computations},
  shorttitle = {{{PennyLane}}},
  author = {Bergholm, Ville and Izaac, Josh and Schuld, Maria and Gogolin, Christian and Ahmed, Shahnawaz and Ajith, Vishnu and Alam, M. Sohaib and Alonso-Linaje, Guillermo and AkashNarayanan, B. and Asadi, Ali and Arrazola, Juan Miguel and Azad, Utkarsh and Banning, Sam and Blank, Carsten and Bromley, Thomas R. and Cordier, Benjamin A. and Ceroni, Jack and Delgado, Alain and Di Matteo, Olivia and Dusko, Amintor and Garg, Tanya and Guala, Diego and Hayes, Anthony and Hill, Ryan and Ijaz, Aroosa and Isacsson, Theodor and Ittah, David and Jahangiri, Soran and Jain, Prateek and Jiang, Edward and Khandelwal, Ankit and Kottmann, Korbinian and Lang, Robert A. and Lee, Christina and Loke, Thomas and Lowe, Angus and McKiernan, Keri and Meyer, Johannes Jakob and Montañez-Barrera, J. A. and Moyard, Romain and Niu, Zeyue and O'Riordan, Lee James and Oud, Steven and Panigrahi, Ashish and Park, Chae-Yeun and Polatajko, Daniel and Quesada, Nicolás and Roberts, Chase and Sá, Nahum and Schoch, Isidor and Shi, Borun and Shu, Shuli and Sim, Sukin and Singh, Arshpreet and Strandberg, Ingrid and Soni, Jay and Száva, Antal and Thabet, Slimane and Vargas-Hernández, Rodrigo A. and Vincent, Trevor and Vitucci, Nicola and Weber, Maurice and Wierichs, David and Wiersema, Roeland and Willmann, Moritz and Wong, Vincent and Zhang, Shaoming and Killoran, Nathan},
  date = {2022},
  number = {arXiv:1811.04968},
  eprint = {arXiv:1811.04968},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.1811.04968},
  abstract = {PennyLane is a Python 3 software framework for differentiable programming of quantum computers. The library provides a unified architecture for near-term quantum computing devices, supporting both qubit and continuous-variable paradigms. PennyLane's core feature is the ability to compute gradients of variational quantum circuits in a way that is compatible with classical techniques such as backpropagation. PennyLane thus extends the automatic differentiation algorithms common in optimization and machine learning to include quantum and hybrid computations. A plugin system makes the framework compatible with any gate-based quantum simulator or hardware. We provide plugins for hardware providers including the Xanadu Cloud, Amazon Braket, and IBM Quantum, allowing PennyLane optimizations to be run on publicly accessible quantum devices. On the classical front, PennyLane interfaces with accelerated machine learning libraries such as TensorFlow, PyTorch, JAX, and Autograd. PennyLane can be used for the optimization of variational quantum eigensolvers, quantum approximate optimization, quantum machine learning models, and many other applications.},
  pubstate = {preprint},
  keywords = {Computer Science - Emerging Technologies,Computer Science - Machine Learning,Physics - Computational Physics,Quantum Physics},
  file = {/Users/boyesjo/Zotero/storage/R674RGHI/Bergholm et al. - 2022 - PennyLane Automatic differentiation of hybrid qua.pdf;/Users/boyesjo/Zotero/storage/UVZKGQU9/1811.html}
}

@article{pesah2021,
  title = {Absence of {{Barren Plateaus}} in {{Quantum Convolutional Neural Networks}}},
  author = {Pesah, Arthur and Cerezo, M. and Wang, Samson and Volkoff, Tyler and Sornborger, Andrew T. and Coles, Patrick J.},
  date = {2021},
  journaltitle = {Physical Review X},
  shortjournal = {Phys. Rev. X},
  volume = {11},
  number = {4},
  pages = {041011},
  issn = {2160-3308},
  doi = {10.1103/PhysRevX.11.041011},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/KY8EVL3B/Pesah et al. - 2021 - Absence of Barren Plateaus in Quantum Convolutiona.pdf}
}

@article{pilarskiOptimalPolicyBernoulli2021,
  title = {Optimal {{Policy}} for {{Bernoulli Bandits}}: {{Computation}} and {{Algorithm Gauge}}},
  shorttitle = {Optimal {{Policy}} for {{Bernoulli Bandits}}},
  author = {Pilarski, Sebastian and Pilarski, Slawomir and Varró, Dániel},
  date = {2021-02},
  journaltitle = {IEEE Transactions on Artificial Intelligence},
  volume = {2},
  number = {1},
  pages = {2--17},
  issn = {2691-4581},
  doi = {10.1109/TAI.2021.3074122},
  abstract = {Bernoulli multi-armed bandits are a reinforcement learning model used to study a variety of choice optimization problems. Often such optimizations concern a finite-time horizon. In principle, statistically optimal policies can be computed via dynamic programming, but doing so is considered infeasible due to prohibitive computational requirements and implementation complexity. Hence, suboptimal algorithms are applied in practice, despite their unknown level of suboptimality. In this article, we demonstrate that optimal policies can be efficiently computed for large time horizons or number of arms thanks to a novel memory organization and indexing scheme. We use optimal policies to gauge the suboptimality of several well-known finite- and infinite-time horizon algorithms including Whittle and Gittins indices, epsilon-greedy, Thompson sampling, and upper-confidence bound (UCB) algorithms. Our simulation study shows that all but one evaluated algorithm perform significantly worse than the optimal policy. The Whittle index offers a nearly optimal strategy for multi-armed Bernoulli bandits despite its suboptimal decisions—up to 10\%—compared to an optimal policy table. Lastly, we discuss optimizations of known algorithms. We derive a novel solution from UCB1-tuned. It outperforms other infinite-time horizon algorithms when dealing with many arms. Impact statement—Bernoulli bandits are a reinforcement learning model used to improve decisions with binary outcomes. They have various applications ranging from headline news selection to clinical trials. Existing bandit algorithms are suboptimal. This article provides the first practical computation method, which determines the optimal decisions in Bernoulli bandits. It provides the lowest achievable decision regret (maximum expected benefit). In clinical trials, where an algorithm selects treatments for subsequent patients, our method can substantially reduce the number of unsuccessfully treated patients—by up to 5×. The optimal strategy is also used for new comprehensive evaluations of well-known suboptimal algorithms. This can significantly improve decision effectiveness in various applications.},
  eventtitle = {{{IEEE Transactions}} on {{Artificial Intelligence}}},
  keywords = {Artificial intelligence,Clinical trials,Computational modeling,epsilon-greedy,Games,Gittins index (GI),multi-armed Bernoulli bandits,optimal policy (OPT),POKER,Random variables,Statistics,Testing,Thompson sampling (TS),upper-confidence bound (UCB),Whittle index (WI)},
  file = {/Users/boyesjo/Zotero/storage/QH4CP86D/Pilarski et al. - 2021 - Optimal Policy for Bernoulli Bandits Computation .pdf;/Users/boyesjo/Zotero/storage/ZQ2J6XFP/9408359.html}
}

@book{python,
  title = {The {{Python}} Language Reference},
  author = {van Rossum, Guido and Drake, Fred L.},
  date = {2010},
  series = {Python Documentation Manual / {{Guido}} van {{Rossum}}; {{Fred L}}. {{Drake}} [Ed.]},
  edition = {Release 3.0.1 [Repr.]},
  number = {Pt. 2},
  publisher = {{Python Software Foundation}},
  location = {{Hampton, NH}},
  isbn = {978-1-4414-1269-0},
  langid = {english},
  pagetotal = {109}
}

@inproceedings{pytorch,
  title = {{{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep Learning Library}}},
  shorttitle = {{{PyTorch}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  date = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}},
  url = {https://papers.nips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html},
  abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.},
  file = {/Users/boyesjo/Zotero/storage/9ZB79T2Z/Paszke et al. - 2019 - PyTorch An Imperative Style, High-Performance Dee.pdf}
}

@software{qiskit,
  title = {Qiskit: {{An Open-source Framework}} for {{Quantum Computing}}},
  shorttitle = {Qiskit/Qiskit},
  author = {Treinish, Matthew and Gambetta, Jay and Nation, Paul and Qiskit-Bot and Kassebaum, Paul and Rodríguez, Diego M. and De La Puente González, Salvador and Shaohan Hu and Lishman, Jake and Krsulich, Kevin and Garrison, Jim and Bello, Luciano and Yu, Jessie and Marques, Manoel and Gacon, Julien and McKay, David and Gomez, Juan and Capelluto, Lauren and Travis-S-IBM and Panigrahi, Ashish and Lerongil and Rafey Iqbal Rahman and Wood, Steve and Toshinari Itoko and Mitchell, Abby and Pozas-Kerstjens, Alex and Wood, Christopher J. and Divyanshu Singh and Drew and Arbel, Eli},
  date = {2022},
  doi = {10.5281/ZENODO.2573505},
  abstract = {Changelog Changed Increased the {$<$}code{$>$}qiskit-terra{$<$}/code{$>$} version to the latest release 0.22.2},
  organization = {{Zenodo}},
  version = {0.39.2}
}

@unpublished{rivera-dean2021,
  title = {Avoiding Local Minima in {{Variational Quantum Algorithms}} with {{Neural Networks}}},
  author = {Rivera-Dean, Javier and Huembeli, Patrick and Acín, Antonio and Bowles, Joseph},
  date = {2021},
  eprint = {2104.02955},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  url = {http://arxiv.org/abs/2104.02955},
  abstract = {Variational Quantum Algorithms have emerged as a leading paradigm for near-term quantum computation. In such algorithms, a parameterized quantum circuit is controlled via a classical optimization method that seeks to minimize a problem-dependent cost function. Although such algorithms are powerful in principle, the non-convexity of the associated cost landscapes and the prevalence of local minima means that local optimization methods such as gradient descent typically fail to reach good solutions. In this work we suggest a method to improve gradient-based approaches to variational quantum circuit optimization, which involves coupling the output of the quantum circuit to a classical neural network. The effect of this neural network is to peturb the cost landscape as a function of its parameters, so that local minima can be escaped or avoided via a modification to the cost landscape itself. We present two algorithms within this framework and numerically benchmark them on small instances of the Max-Cut optimization problem. We show that the method is able to reach deeper minima and lower cost values than standard gradient descent based approaches. Moreover, our algorithms require essentially the same number of quantum circuit evaluations per optimization step as the standard approach since, unlike the gradient with respect to the circuit, the neural network updates can be estimated in parallel via the backpropagation method. More generally, our approach suggests that relaxing the cost landscape is a fruitful path to improving near-term quantum computing algorithms.},
  keywords = {Quantum Physics},
  file = {/Users/boyesjo/Zotero/storage/V86KM4D8/Rivera-Dean et al. - 2021 - Avoiding local minima in Variational Quantum Algor.pdf;/Users/boyesjo/Zotero/storage/G83B4E5I/2104.html}
}

@article{robbins1952,
  title = {Some Aspects of the Sequential Design of Experiments},
  author = {Robbins, Herbert},
  date = {1952},
  journaltitle = {Bulletin of the American Mathematical Society},
  shortjournal = {Bull. Amer. Math. Soc.},
  volume = {58},
  number = {5},
  pages = {527--535},
  issn = {0273-0979, 1088-9485},
  doi = {10.1090/S0002-9904-1952-09620-8},
  langid = {english},
  keywords = {Meta},
  file = {/Users/boyesjo/Zotero/storage/BVZV4J3Q/Robbins - 1952 - Some aspects of the sequential design of experimen.pdf}
}

@article{russo2018,
  title = {A {{Tutorial}} on {{Thompson Sampling}}},
  author = {Russo, Daniel J. and Roy, Benjamin Van and Kazerouni, Abbas and Osband, Ian and Wen, Zheng},
  date = {2018},
  journaltitle = {Foundations and Trends® in Machine Learning},
  shortjournal = {MAL},
  volume = {11},
  number = {1},
  pages = {1--96},
  publisher = {{Now Publishers, Inc.}},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000070},
  abstract = {A Tutorial on Thompson Sampling},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/WUJ7689X/russo2018.pdf;/Users/boyesjo/Zotero/storage/MIILQEHC/MAL-070.html}
}

@article{saggio2021,
  title = {Experimental Quantum Speed-up in Reinforcement Learning Agents},
  author = {Saggio, V. and Asenbeck, B. E. and Hamann, A. and Strömberg, T. and Schiansky, P. and Dunjko, V. and Friis, N. and Harris, N. C. and Hochberg, M. and Englund, D. and Wölk, S. and Briegel, H. J. and Walther, P.},
  date = {2021},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {591},
  number = {7849},
  pages = {229--233},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-021-03242-7},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/TFGLBVKI/Saggio et al. - 2021 - Experimental quantum speed-up in reinforcement lea.pdf}
}

@article{sb3,
  title = {Stable-{{Baselines3}}: {{Reliable Reinforcement Learning Implementations}}},
  author = {Raffin, Antonin and Hill, Ashley and Gleave, Adam and Kanervisto, Anssi and Ernestus, Maximilliam and Dormann, Noah},
  date = {2021},
  journaltitle = {Journal of Machine Learning Research},
  volume = {22},
  number = {268},
  pages = {1--8},
  url = {http://jmlr.org/papers/v22/20-1364.html}
}

@book{schuld2018,
  title = {Supervised {{Learning}} with {{Quantum Computers}}},
  author = {Schuld, Maria and Petruccione, Francesco},
  date = {2018},
  series = {Quantum {{Science}} and {{Technology}}},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-96424-9},
  isbn = {978-3-319-96423-2},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/TRGE6439/Schuld and Petruccione - 2018 - Supervised Learning with Quantum Computers.pdf}
}

@article{schuld2019,
  title = {Evaluating Analytic Gradients on Quantum Hardware},
  author = {Schuld, Maria and Bergholm, Ville and Gogolin, Christian and Izaac, Josh and Killoran, Nathan},
  date = {2019},
  journaltitle = {Physical Review A},
  shortjournal = {Phys. Rev. A},
  volume = {99},
  number = {3},
  pages = {032331},
  issn = {2469-9926, 2469-9934},
  doi = {10.1103/PhysRevA.99.032331},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/A3UFY4PQ/Schuld et al. - 2019 - Evaluating analytic gradients on quantum hardware.pdf}
}

@article{schuld2019a,
  title = {Quantum {{Machine Learning}} in {{Feature Hilbert Spaces}}},
  author = {Schuld, Maria and Killoran, Nathan},
  date = {2019},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {122},
  number = {4},
  pages = {040504},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.122.040504},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/NVJBCU98/Schuld and Killoran - 2019 - Quantum Machine Learning in Feature Hilbert Spaces.pdf}
}

@book{schuld2021,
  title = {Machine {{Learning}} with {{Quantum Computers}}},
  author = {Schuld, Maria and Petruccione, Francesco},
  date = {2021},
  series = {Quantum {{Science}} and {{Technology}}},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-83098-4},
  isbn = {978-3-030-83097-7},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/N468MYGQ/textbook 2nd ed.pdf}
}

@article{schuld2021a,
  title = {The Effect of Data Encoding on the Expressive Power of Variational Quantum Machine Learning Models},
  author = {Schuld, Maria and Sweke, Ryan and Meyer, Johannes Jakob},
  date = {2021},
  journaltitle = {Physical Review A},
  shortjournal = {Phys. Rev. A},
  volume = {103},
  number = {3},
  eprint = {2008.08605},
  eprinttype = {arxiv},
  eprintclass = {quant-ph, stat},
  pages = {032430},
  issn = {2469-9926, 2469-9934},
  doi = {10.1103/PhysRevA.103.032430},
  abstract = {Quantum computers can be used for supervised learning by treating parametrised quantum circuits as models that map data inputs to predictions. While a lot of work has been done to investigate practical implications of this approach, many important theoretical properties of these models remain unknown. Here we investigate how the strategy with which data is encoded into the model influences the expressive power of parametrised quantum circuits as function approximators. We show that one can naturally write a quantum model as a partial Fourier series in the data, where the accessible frequencies are determined by the nature of the data encoding gates in the circuit. By repeating simple data encoding gates multiple times, quantum models can access increasingly rich frequency spectra. We show that there exist quantum models which can realise all possible sets of Fourier coefficients, and therefore, if the accessible frequency spectrum is asymptotically rich enough, such models are universal function approximators.},
  keywords = {Quantum Physics,Statistics - Machine Learning},
  file = {/Users/boyesjo/Zotero/storage/9WWFLMXQ/Schuld et al. - 2021 - The effect of data encoding on the expressive powe.pdf;/Users/boyesjo/Zotero/storage/RVVRVWND/2008.html}
}

@online{sharma2022,
  title = {Using a {{Multi-Armed Bandit}} with {{Thompson Sampling}} to {{Identify Responsive Dashers}}},
  author = {Sharma, Arjun},
  date = {2022},
  url = {https://doordash.engineering/2022/03/15/using-a-multi-armed-bandit-with-thompson-sampling-to-identify-responsive-dashers/},
  abstract = {Epsilon-Greedy, The Upper Confidence Bound, Thompson Sampling: which is the best Multi-armed bandit algorithm for promotion optimization?},
  langid = {american},
  organization = {{DoorDash Engineering Blog}},
  file = {/Users/boyesjo/Zotero/storage/V3EH7RWW/using-a-multi-armed-bandit-with-thompson-sampling-to-identify-responsive-dashers.html}
}

@inproceedings{shor1994,
  title = {Algorithms for Quantum Computation: Discrete Logarithms and Factoring},
  shorttitle = {Algorithms for Quantum Computation},
  booktitle = {Proceedings 35th {{Annual Symposium}} on {{Foundations}} of {{Computer Science}}},
  author = {Shor, Peter W.},
  date = {1994},
  pages = {124--134},
  publisher = {{IEEE}},
  location = {{Santa Fe, New Mexico, United States of America}},
  doi = {10.1109/SFCS.1994.365700},
  isbn = {978-0-8186-6580-6}
}

@article{silver2016,
  title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  options = {useprefix=true},
  date = {2016},
  journaltitle = {Nature},
  volume = {529},
  number = {7587},
  pages = {484--489},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature16961},
  abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
  issue = {7587},
  langid = {english},
  keywords = {Computational science,Computer science,Reward}
}

@article{skolik2022,
  title = {Quantum Agents in the {{Gym}}: A Variational Quantum Algorithm for Deep {{Q-learning}}},
  shorttitle = {Quantum Agents in the {{Gym}}},
  author = {Skolik, Andrea and Jerbi, Sofiene and Dunjko, Vedran},
  date = {2022},
  journaltitle = {Quantum},
  shortjournal = {Quantum},
  volume = {6},
  eprint = {2103.15084},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  pages = {720},
  issn = {2521-327X},
  doi = {10.22331/q-2022-05-24-720},
  abstract = {Quantum machine learning (QML) has been identified as one of the key fields that could reap advantages from near-term quantum devices, next to optimization and quantum chemistry. Research in this area has focused primarily on variational quantum algorithms (VQAs), and several proposals to enhance supervised, unsupervised and reinforcement learning (RL) algorithms with VQAs have been put forward. Out of the three, RL is the least studied and it is still an open question whether VQAs can be competitive with state-of-the-art classical algorithms based on neural networks (NNs) even on simple benchmark tasks. In this work, we introduce a training method for parametrized quantum circuits (PQCs) that can be used to solve RL tasks for discrete and continuous state spaces based on the deep Q-learning algorithm. We investigate which architectural choices for quantum Q-learning agents are most important for successfully solving certain types of environments by performing ablation studies for a number of different data encoding and readout strategies. We provide insight into why the performance of a VQA-based Q-learning algorithm crucially depends on the observables of the quantum model and show how to choose suitable observables based on the learning task at hand. To compare our model against the classical DQN algorithm, we perform an extensive hyperparameter search of PQCs and NNs with varying numbers of parameters. We confirm that similar to results in classical literature, the architectural choices and hyperparameters contribute more to the agents' success in a RL setting than the number of parameters used in the model. Finally, we show when recent separation results between classical and quantum agents for policy gradient RL can be extended to inferring optimal Q-values in restricted families of environments.},
  keywords = {quantum computation,Quantum Physics,Reinforcement learning},
  file = {/Users/boyesjo/Zotero/storage/ANV99XF7/Skolik et al. - 2022 - Quantum agents in the Gym a variational quantum a.pdf;/Users/boyesjo/Zotero/storage/7JFZLFCN/2103.html}
}

@article{slivkins2019,
  title = {Introduction to {{Multi-Armed Bandits}}},
  author = {Slivkins, Aleksandrs},
  date = {2019},
  journaltitle = {Foundations and Trends® in Machine Learning},
  shortjournal = {FNT in Machine Learning},
  volume = {12},
  number = {1-2},
  pages = {1--286},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000068},
  langid = {english},
  keywords = {Bandits},
  file = {/Users/boyesjo/Zotero/storage/VZ6KSIVP/Slivkins - 2019 - Introduction to Multi-Armed Bandits.pdf}
}

@article{suzuki2020,
  title = {Amplitude Estimation without Phase Estimation},
  author = {Suzuki, Yohichi and Uno, Shumpei and Raymond, Rudy and Tanaka, Tomoki and Onodera, Tamiya and Yamamoto, Naoki},
  date = {2020},
  journaltitle = {Quantum Information Processing},
  shortjournal = {Quantum Inf Process},
  volume = {19},
  number = {2},
  eprint = {1904.10246},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  pages = {75},
  issn = {1570-0755, 1573-1332},
  doi = {10.1007/s11128-019-2565-2},
  abstract = {This paper focuses on the quantum amplitude estimation algorithm, which is a core subroutine in quantum computation for various applications. The conventional approach for amplitude estimation is to use the phase estimation algorithm, which consists of many controlled amplification operations followed by a quantum Fourier transform. However, the whole procedure is hard to implement with current and near-term quantum computers. In this paper, we propose a quantum amplitude estimation algorithm without the use of expensive controlled operations; the key idea is to utilize the maximum likelihood estimation based on the combined measurement data produced from quantum circuits with different numbers of amplitude amplification operations. Numerical simulations we conducted demonstrate that our algorithm asymptotically achieves nearly the optimal quantum speedup with a reasonable circuit length.},
  keywords = {Quantum Physics},
  file = {/Users/boyesjo/Zotero/storage/I6ZLXUDP/Suzuki et al. - 2020 - Amplitude estimation without phase estimation.pdf;/Users/boyesjo/Zotero/storage/ZRT7845W/1904.html}
}

@article{sweke2020,
  title = {Stochastic Gradient Descent for Hybrid Quantum-Classical Optimization},
  author = {Sweke, Ryan and Wilde, Frederik and Meyer, Johannes and Schuld, Maria and Faehrmann, Paul K. and Meynard-Piganeau, Barthélémy and Eisert, Jens},
  date = {2020},
  journaltitle = {Quantum},
  shortjournal = {Quantum},
  volume = {4},
  eprint = {1910.01155},
  eprinttype = {arxiv},
  pages = {314},
  issn = {2521-327X},
  doi = {10.22331/q-2020-08-31-314},
  abstract = {Within the context of hybrid quantum-classical optimization, gradient descent based optimizers typically require the evaluation of expectation values with respect to the outcome of parameterized quantum circuits. In this work, we explore the consequences of the prior observation that estimation of these quantities on quantum hardware results in a form of stochastic gradient descent optimization. We formalize this notion, which allows us to show that in many relevant cases, including VQE, QAOA and certain quantum classifiers, estimating expectation values with \$k\$ measurement outcomes results in optimization algorithms whose convergence properties can be rigorously well understood, for any value of \$k\$. In fact, even using single measurement outcomes for the estimation of expectation values is sufficient. Moreover, in many settings the required gradients can be expressed as linear combinations of expectation values -- originating, e.g., from a sum over local terms of a Hamiltonian, a parameter shift rule, or a sum over data-set instances -- and we show that in these cases \$k\$-shot expectation value estimation can be combined with sampling over terms of the linear combination, to obtain "doubly stochastic" gradient descent optimizers. For all algorithms we prove convergence guarantees, providing a framework for the derivation of rigorous optimization results in the context of near-term quantum devices. Additionally, we explore numerically these methods on benchmark VQE, QAOA and quantum-enhanced machine learning tasks and show that treating the stochastic settings as hyper-parameters allows for state-of-the-art results with significantly fewer circuit executions and measurements.},
  keywords = {Computer Science - Machine Learning,Quantum Physics},
  file = {/Users/boyesjo/Zotero/storage/RILSKGC9/Sweke et al. - 2020 - Stochastic gradient descent for hybrid quantum-cla.pdf;/Users/boyesjo/Zotero/storage/Y43MJVT6/1910.html}
}

@article{takaki2021,
  title = {Learning Temporal Data with a Variational Quantum Recurrent Neural Network},
  author = {Takaki, Yuto and Mitarai, Kosuke and Negoro, Makoto and Fujii, Keisuke and Kitagawa, Masahiro},
  date = {2021},
  journaltitle = {Physical Review A},
  shortjournal = {Phys. Rev. A},
  volume = {103},
  number = {5},
  pages = {052414},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevA.103.052414},
  abstract = {We propose a method for learning temporal data using a parametrized quantum circuit. We use the circuit that has a similar structure as the recurrent neural network, which is one of the standard approaches employed for this type of machine learning task. Some of the qubits in the circuit are utilized for memorizing past data, while others are measured and initialized at each time step for obtaining predictions and encoding a new input datum. The proposed approach utilizes the tensor product structure to get nonlinearity with respect to the inputs. Fully controllable, ensemble quantum systems such as an NMR quantum computer are a suitable choice of an experimental platform for this proposal. We demonstrate its capability with simple numerical simulations, in which we test the proposed method for the task of predicting cosine and triangular waves and quantum spin dynamics. Finally, we analyze the dependency of its performance on the interaction strength among the qubits in numerical simulation and find that there is an appropriate range of the strength. This work provides a way to exploit complex quantum dynamics for learning temporal data.},
  file = {/Users/boyesjo/Zotero/storage/E43RNCNH/Takaki et al. - 2021 - Learning temporal data with a variational quantum .pdf;/Users/boyesjo/Zotero/storage/IVEWQNRI/PhysRevA.103.html}
}

@article{thompson1933,
  title = {On the {{Likelihood}} That {{One Unknown Probability Exceeds Another}} in {{View}} of {{Evidence}} of {{Two Samples}}},
  author = {Thompson, William R.},
  date = {1933},
  journaltitle = {Biometrika},
  shortjournal = {Biometrika},
  volume = {25},
  number = {3-4},
  pages = {285--294},
  issn = {0006-3444},
  doi = {10.1093/biomet/25.3-4.285},
  keywords = {Meta},
  file = {/Users/boyesjo/Zotero/storage/F6XYZJ5C/THOMPSON - 1933 - ON THE LIKELIHOOD THAT ONE UNKNOWN PROBABILITY EXC.pdf;/Users/boyesjo/Zotero/storage/Q676XX2Z/200862.html}
}

@article{tokic2011,
  title = {Value-Difference Based Exploration: Adaptive Control between Epsilon-Greedy and Softmax},
  shorttitle = {Value-Difference Based Exploration},
  author = {Tokic, Michel and Palm, Günther},
  date = {2011-10-04},
  journaltitle = {Lecture Notes in Computer Science},
  doi = {10.1007/978-3-642-24455-1_33},
  abstract = {This paper proposes Value-Difference Based Exploration combined with Softmax action selection (VDBE-Softmax) a},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/FKV4PNZQ/Tokic and Palm - 2011 - Value-difference based exploration adaptive contr.pdf}
}

@article{torlai2020,
  title = {Precise Measurement of Quantum Observables with Neural-Network Estimators},
  author = {Torlai, Giacomo and Mazzola, Guglielmo and Carleo, Giuseppe and Mezzacapo, Antonio},
  date = {2020},
  journaltitle = {Physical Review Research},
  shortjournal = {Phys. Rev. Research},
  volume = {2},
  number = {2},
  pages = {022060},
  issn = {2643-1564},
  doi = {10.1103/PhysRevResearch.2.022060},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/7NBMA6D5/Torlai et al. - 2020 - Precise measurement of quantum observables with ne.pdf}
}

@unpublished{verdon2019,
  title = {Learning to Learn with Quantum Neural Networks via Classical Neural Networks},
  author = {Verdon, Guillaume and Broughton, Michael and McClean, Jarrod Ryan and Sung, Kevin Jeffery and Babbush, Ryan and Jiang, Zhang and Neven, Hartmut and Mohseni, Masoud},
  date = {2019},
  eprint = {1907.05415},
  eprinttype = {arxiv},
  url = {https://arxiv.org/abs/1907.05415},
  file = {/Users/boyesjo/Zotero/storage/NVTWQE4T/Verdon et al. - 2019 - Learning to learn with quantum neural networks via.pdf}
}

@inproceedings{vermorel2005,
  title = {Multi-Armed {{Bandit Algorithms}} and {{Empirical Evaluation}}},
  booktitle = {Machine {{Learning}}: {{ECML}} 2005},
  author = {Vermorel, Joannès and Mohri, Mehryar},
  editor = {Gama, João and Camacho, Rui and Brazdil, Pavel B. and Jorge, Alípio Mário and Torgo, Luís},
  date = {2005},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {437--448},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/11564096_42},
  abstract = {The multi-armed bandit problem for a gambler is to decide which arm of a K-slot machine to pull to maximize his total reward in a series of trials. Many real-world learning and optimization problems can be modeled in this way. Several strategies or algorithms have been proposed as a solution to this problem in the last two decades, but, to our knowledge, there has been no common evaluation of these algorithms.},
  isbn = {978-3-540-31692-3},
  langid = {english},
  keywords = {Bandit Problem,Bandits,Content Distribution Network,Empirical,Empirical Evaluation,Greedy Strategy,Reward Distribution},
  file = {/Users/boyesjo/Zotero/storage/SKUVYUAY/Vermorel and Mohri - 2005 - Multi-armed Bandit Algorithms and Empirical Evalua.pdf}
}

@article{wan2022,
  title = {Quantum {{Multi-Armed Bandits}} and {{Stochastic Linear Bandits Enjoy Logarithmic Regrets}}},
  author = {Wan, Zongqi and Zhang, Zhijie and Li, Tongyang and Zhang, Jialin and Sun, Xiaoming},
  date = {2022},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2205.14988},
  abstract = {Multi-arm bandit (MAB) and stochastic linear bandit (SLB) are important models in reinforcement learning, and it is well-known that classical algorithms for bandits with time horizon \$T\$ suffer \$Ω(\textbackslash sqrt\{T\})\$ regret. In this paper, we study MAB and SLB with quantum reward oracles and propose quantum algorithms for both models with \$O(\textbackslash mbox\{poly\}(\textbackslash log T))\$ regrets, exponentially improving the dependence in terms of \$T\$. To the best of our knowledge, this is the first provable quantum speedup for regrets of bandit problems and in general exploitation in reinforcement learning. Compared to previous literature on quantum exploration algorithms for MAB and reinforcement learning, our quantum input model is simpler and only assumes quantum oracles for each individual arm.},
  version = {1},
  keywords = {Bandits,FOS: Computer and information sciences,FOS: Physical sciences,Machine Learning (cs.LG),quantum computation,Quantum Physics (quant-ph)},
  file = {/Users/boyesjo/Zotero/storage/9T7A3HYV/Wan et al. - 2022 - Quantum Multi-Armed Bandits and Stochastic Linear .pdf}
}

@article{wang2014,
  title = {Online {{Feature Selection}} and {{Its Applications}}},
  author = {Wang, Jialei and Zhao, Peilin and Hoi, Steven C.H. and Jin, Rong},
  date = {2014-03},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {26},
  number = {3},
  pages = {698--710},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2013.32},
  abstract = {Feature selection is an important technique for data mining. Despite its importance, most studies of feature selection are restricted to batch learning. Unlike traditional batch learning methods, online learning represents a promising family of efficient and scalable machine learning algorithms for large-scale applications. Most existing studies of online learning require accessing all the attributes/features of training instances. Such a classical setting is not always appropriate for real-world applications when data instances are of high dimensionality or it is expensive to acquire the full set of attributes/features. To address this limitation, we investigate the problem of online feature selection (OFS) in which an online learner is only allowed to maintain a classifier involved only a small and fixed number of features. The key challenge of online feature selection is how to make accurate prediction for an instance using a small number of active features. This is in contrast to the classical setup of online learning where all the features can be used for prediction. We attempt to tackle this challenge by studying sparsity regularization and truncation techniques. Specifically, this article addresses two different tasks of online feature selection: 1) learning with full input, where an learner is allowed to access all the features to decide the subset of active features, and 2) learning with partial input, where only a limited number of features is allowed to be accessed for each instance by the learner. We present novel algorithms to solve each of the two problems and give their performance analysis. We evaluate the performance of the proposed algorithms for online feature selection on several public data sets, and demonstrate their applications to real-world problems including image classification in computer vision and microarray gene expression analysis in bioinformatics. The encouraging results of our experiments validate the efficacy and efficiency of the proposed techniques.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  keywords = {Algorithm design and analysis,big data analytics,Bioinformatics,classification,Classification algorithms,Data mining,Feature selection,large-scale data mining,Machine learning algorithms,online learning,Prediction algorithms,Training},
  file = {/Users/boyesjo/Zotero/storage/EPQ5FPVS/Wang et al. - 2014 - Online Feature Selection and Its Applications.pdf;/Users/boyesjo/Zotero/storage/4BNYIHZ4/6522405.html}
}

@article{wang2021,
  title = {Quantum {{Exploration Algorithms}} for {{Multi-Armed Bandits}}},
  author = {Wang, Daochen and You, Xuchen and Li, Tongyang and Childs, Andrew M.},
  date = {2021},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {35},
  number = {11},
  pages = {10102--10110},
  issn = {2374-3468},
  doi = {10.1609/aaai.v35i11.17212},
  abstract = {Identifying the best arm of a multi-armed bandit is a central problem in bandit optimization. We study a quantum computational version of this problem with coherent oracle access to states encoding the reward probabilities of each arm as quantum amplitudes. Specifically, we provide an algorithm to find the best arm with fixed confidence based on variable-time amplitude amplification and estimation. This algorithm gives a quadratic speedup compared to the best possible classical result in terms of query complexity. We also prove a matching quantum lower bound (up to poly-logarithmic factors).},
  issue = {11},
  langid = {english},
  keywords = {Bandits,Online Learning & Bandits,quantum computation},
  file = {/Users/boyesjo/Zotero/storage/7NZUU42H/2007.07049.pdf}
}

@article{wang2021a,
  title = {Noise-Induced Barren Plateaus in Variational Quantum Algorithms},
  author = {Wang, Samson and Fontana, Enrico and Cerezo, M. and Sharma, Kunal and Sone, Akira and Cincio, Lukasz and Coles, Patrick J.},
  date = {2021},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {6961},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-27045-6},
  abstract = {Abstract                            Variational Quantum Algorithms (VQAs) may be a path to quantum advantage on Noisy Intermediate-Scale Quantum (NISQ) computers. A natural question is whether noise on NISQ devices places fundamental limitations on VQA performance. We rigorously prove a serious limitation for noisy VQAs, in that the noise causes the training landscape to have a barren plateau (i.e., vanishing gradient). Specifically, for the local Pauli noise considered, we prove that the gradient vanishes exponentially in the number of qubits               n               if the depth of the ansatz grows linearly with               n               . These noise-induced barren plateaus (NIBPs) are conceptually different from noise-free barren plateaus, which are linked to random parameter initialization. Our result is formulated for a generic ansatz that includes as special cases the Quantum Alternating Operator Ansatz and the Unitary Coupled Cluster Ansatz, among others. For the former, our numerical heuristics demonstrate the NIBP phenomenon for a realistic hardware noise model.},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/A8N8BDQK/Wang et al. - 2021 - Noise-induced barren plateaus in variational quant.pdf}
}

@article{wiebe2012,
  title = {Quantum {{Algorithm}} for {{Data Fitting}}},
  author = {Wiebe, Nathan and Braun, Daniel and Lloyd, Seth},
  date = {2012},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {109},
  number = {5},
  pages = {050505},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.109.050505},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/7UGDK5EQ/Wiebe et al. - 2012 - Quantum Algorithm for Data Fitting.pdf}
}

@unpublished{wierichs2021,
  title = {General Parameter-Shift Rules for Quantum Gradients},
  author = {Wierichs, David and Izaac, Josh and Wang, Cody and Lin, Cedric Yen-Yu},
  date = {2021},
  eprint = {2107.12390},
  eprinttype = {arxiv},
  eprintclass = {quant-ph},
  url = {http://arxiv.org/abs/2107.12390},
  abstract = {Variational quantum algorithms are ubiquitous in applications of noisy intermediate-scale quantum computers. Due to the structure of conventional parametrized quantum gates, the evaluated functions typically are finite Fourier series of the input parameters. In this work, we use this fact to derive new, general parameter-shift rules for single-parameter gates, and provide closed-form expressions to apply them. These rules are then extended to multi-parameter quantum gates by combining them with the stochastic parameter-shift rule. We perform a systematic analysis of quantum resource requirements for each rule, and show that a reduction in resources is possible for higher-order derivatives. Using the example of the quantum approximate optimization algorithm, we show that the generalized parameter-shift rule can reduce the number of circuit evaluations significantly when computing derivatives with respect to parameters that feed into many gates. Our approach additionally reproduces reconstructions of the evaluated function up to a chosen order, leading to known generalizations of the Rotosolve optimizer and new extensions of the quantum analytic descent optimization algorithm.},
  keywords = {Quantum Physics},
  file = {/Users/boyesjo/Zotero/storage/F6ACI4EZ/Wierichs et al. - 2021 - General parameter-shift rules for quantum gradient.pdf;/Users/boyesjo/Zotero/storage/HL2TC82L/2107.html}
}

@article{wu2023,
  title = {Quantum {{Heavy-tailed Bandits}}},
  author = {Wu, Yulian and Guan, Chaowen and Aggarwal, Vaneet and Wang, Di},
  date = {2023},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2301.09680},
  abstract = {In this paper, we study multi-armed bandits (MAB) and stochastic linear bandits (SLB) with heavy-tailed rewards and quantum reward oracle. Unlike the previous work on quantum bandits that assumes bounded/sub-Gaussian distributions for rewards, here we investigate the quantum bandits problem under a weaker assumption that the distributions of rewards only have bounded \$(1+v)\$-th moment for some \$v\textbackslash in (0,1]\$. In order to achieve regret improvements for heavy-tailed bandits, we first propose a new quantum mean estimator for heavy-tailed distributions, which is based on the Quantum Monte Carlo Mean Estimator and achieves a quadratic improvement of estimation error compared to the classical one. Based on our quantum mean estimator, we focus on quantum heavy-tailed MAB and SLB and propose quantum algorithms based on the Upper Confidence Bound (UCB) framework for both problems with \$\textbackslash Tilde\{O\}(T\^\{\textbackslash frac\{1-v\}\{1+v\}\})\$ regrets, polynomially improving the dependence in terms of \$T\$ as compared to classical (near) optimal regrets of \$\textbackslash Tilde\{O\}(T\^\{\textbackslash frac\{1\}\{1+v\}\})\$, where \$T\$ is the number of rounds. Finally, experiments also support our theoretical results and show the effectiveness of our proposed methods.},
  version = {1},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG)}
}

@article{yan2020,
  title = {Nonlinear Quantum Neuron: {{A}} Fundamental Building Block for Quantum Neural Networks},
  shorttitle = {Nonlinear Quantum Neuron},
  author = {Yan, Shilu and Qi, Hongsheng and Cui, Wei},
  date = {2020},
  journaltitle = {Physical Review A},
  shortjournal = {Phys. Rev. A},
  volume = {102},
  number = {5},
  pages = {052421},
  issn = {2469-9926, 2469-9934},
  doi = {10.1103/PhysRevA.102.052421},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/VZBND72G/Yan et al. - 2020 - Nonlinear quantum neuron A fundamental building b.pdf}
}

@article{ying2021,
  title = {Optimal {{Policies}} for {{Quantum Markov Decision Processes}}},
  author = {Ying, Ming-Sheng and Feng, Yuan and Ying, Sheng-Gang},
  date = {2021},
  journaltitle = {International Journal of Automation and Computing},
  shortjournal = {Int. J. Autom. Comput.},
  volume = {18},
  number = {3},
  pages = {410--421},
  issn = {1751-8520},
  doi = {10.1007/s11633-021-1278-z},
  abstract = {Markov decision process (MDP) offers a general framework for modelling sequential decision making where outcomes are random. In particular, it serves as a mathematical framework for reinforcement learning. This paper introduces an extension of MDP, namely quantum MDP (qMDP), that can serve as a mathematical model of decision making about quantum systems. We develop dynamic programming algorithms for policy evaluation and finding optimal policies for qMDPs in the case of finite-horizon. The results obtained in this paper provide some useful mathematical tools for reinforcement learning techniques applied to the quantum world.},
  langid = {english},
  keywords = {decision making,dynamic programming,quantum computation,quantum machine learning,Quantum Markov decision processes,reinforcement learning},
  file = {/Users/boyesjo/Zotero/storage/472HIASH/Ying et al. - 2021 - Optimal Policies for Quantum Markov Decision Proce.pdf}
}

@article{zalka1999,
  title = {Grover’s Quantum Searching Algorithm Is Optimal},
  author = {Zalka, Christof},
  date = {1999},
  journaltitle = {Physical Review A},
  shortjournal = {Phys. Rev. A},
  volume = {60},
  number = {4},
  pages = {2746--2751},
  issn = {1050-2947, 1094-1622},
  doi = {10.1103/PhysRevA.60.2746},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/3NWEGFDC/Zalka - 1999 - Grover’s quantum searching algorithm is optimal.pdf}
}

@article{zeng2022,
  title = {A {{Multi-Classification Hybrid Quantum Neural Network Using}} an {{All-Qubit Multi-Observable Measurement Strategy}}},
  author = {Zeng, Yi and Wang, Hao and He, Jin and Huang, Qijun and Chang, Sheng},
  date = {2022},
  journaltitle = {Entropy},
  shortjournal = {Entropy},
  volume = {24},
  number = {3},
  pages = {394},
  issn = {1099-4300},
  doi = {10.3390/e24030394},
  abstract = {Quantum machine learning is a promising application of quantum computing for data classification. However, most of the previous research focused on binary classification, and there are few studies on multi-classification. The major challenge comes from the limitations of near-term quantum devices on the number of qubits and the size of quantum circuits. In this paper, we propose a hybrid quantum neural network to implement multi-classification of a real-world dataset. We use an average pooling downsampling strategy to reduce the dimensionality of samples, and we design a ladder-like parameterized quantum circuit to disentangle the input states. Besides this, we adopt an all-qubit multi-observable measurement strategy to capture sufficient hidden information from the quantum system. The experimental results show that our algorithm outperforms the classical neural network and performs especially well on different multi-class datasets, which provides some enlightenment for the application of quantum computing to real-world data on near-term quantum processors.},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/JW56B9NC/Zeng et al. - 2022 - A Multi-Classification Hybrid Quantum Neural Netwo.pdf}
}

@article{zhong2020,
  title = {Quantum Computational Advantage Using Photons},
  author = {Zhong, Han-Sen and Wang, Hui and Deng, Yu-Hao and Chen, Ming-Cheng and Peng, Li-Chao and Luo, Yi-Han and Qin, Jian and Wu, Dian and Ding, Xing and Hu, Yi and Hu, Peng and Yang, Xiao-Yan and Zhang, Wei-Jun and Li, Hao and Li, Yuxuan and Jiang, Xiao and Gan, Lin and Yang, Guangwen and You, Lixing and Wang, Zhen and Li, Li and Liu, Nai-Le and Lu, Chao-Yang and Pan, Jian-Wei},
  date = {2020},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {370},
  number = {6523},
  pages = {1460--1463},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.abe8770},
  abstract = {A light approach to quantum advantage                            Quantum computational advantage or supremacy is a long-anticipated milestone toward practical quantum computers. Recent work claimed to have reached this point, but subsequent work managed to speed up the classical simulation and pointed toward a sample size–dependent loophole. Quantum computational advantage, rather than being a one-shot experimental proof, will be the result of a long-term competition between quantum devices and classical simulation. Zhong               et al.               sent 50 indistinguishable single-mode squeezed states into a 100-mode ultralow-loss interferometer and sampled the output using 100 high-efficiency single-photon detectors. By obtaining up to 76-photon coincidence, yielding a state space dimension of about 10               30               , they measured a sampling rate that is about 10               14               -fold faster than using state-of-the-art classical simulation strategies and supercomputers.                                         Science               , this issue p.               1460                        ,              Quantum computational advantage is demonstrated using boson sampling with photons.           ,                             Quantum computers promise to perform certain tasks that are believed to be intractable to classical computers. Boson sampling is such a task and is considered a strong candidate to demonstrate the quantum computational advantage. We performed Gaussian boson sampling by sending 50 indistinguishable single-mode squeezed states into a 100-mode ultralow-loss interferometer with full connectivity and random matrix—the whole optical setup is phase-locked—and sampling the output using 100 high-efficiency single-photon detectors. The obtained samples were validated against plausible hypotheses exploiting thermal states, distinguishable photons, and uniform distribution. The photonic quantum computer,               Jiuzhang               , generates up to 76 output photon clicks, which yields an output state-space dimension of 10               30               and a sampling rate that is faster than using the state-of-the-art simulation strategy and supercomputers by a factor of \textasciitilde 10               14               .},
  langid = {english},
  file = {/Users/boyesjo/Zotero/storage/TAMTV4VM/Zhong et al. - 2020 - Quantum computational advantage using photons.pdf}
}
