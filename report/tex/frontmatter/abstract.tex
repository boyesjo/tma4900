\chapter{Abstract}

The bandit problem is a fundamental problem in sequential decision-making.
In it, an agent must decide between different arms, each with an unknown reward distribution, and try to maximise all received rewards.
Real-world applications include clinical trials, recommender systems, portfolio optimisation and more.
This thesis studies the problem and how it can be solved with modern technologies, namely quantum computing and neural-network-based reinforcement learning.
These are then compared with classical, bandit-specific algorithms.

A primary focus of the thesis is the quantum UCB algorithm.
It uses a quantum Monte Carlo subroutine to estimate the reward means more precisely than is possible classically, but requires rewards received in quantum-mechanical superposition states.
Numerical comparisons with classical UCB and Thompson sampling indicate that the quantum algorithm can outperform the classical algorithms, but only for hard instances.
Quantum advantage requires numerous turns and highly correlated arms.
Further research is needed to determine what applications permit the use of the quantum algorithm and that are difficult enough to warrant its use.

General reinforcement learning algorithms, not specifically designed for the bandit problem, are also tested on it.
It is observed that they struggle to solve the tested bandit instances.
This is likely due to poor state representations or reward functions.
While future work could find better setups for these algorithms, it is likely that bandit-specific algorithms will remain the best choice for the bandit problem; with the effort that may be required to match the specific algorithms, the benefit of using a general tool is lost.

To conclude, the thesis finds quantum computing a useful for the bandit problem, while general reinforcement learning algorithms appear not so.
More studies are needed to determine what conditions are needed for quantum benefits and to test the algorithm on different reward distributions and arm numbers.
Future work could consider non-stochastic bandits or attempt to find a better quantum bandit algorithm, building something inherently quantum instead of extending classical algorithms.

\cleardoublepage