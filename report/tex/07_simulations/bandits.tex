\section{Algorithms for the multi-armed bandit problem}
By producing better predictions of the rewards of the arms, the QUCB algorithm promises to outperform classical algorithms in the multi-armed bandit problem.
While the upper bound shown in \cref{sec:wan2022} implies QUCB advantage, it does not necessarily mean it is supreme in all cases or even on average.
It is therefore of much interest to test it on a variety of problems and compare its average performance to other algorithms â€” not only with the classical UCB to which it is compared in the original paper, but also with the more performant Thompson sampling algorithm\footnote{Q.v. \cref{chap:bandits}.}.
The UCB algorithm and Thompson algorithms were implemented in a straight-forward manner per the descriptions in \cref{sec:ucb,sec:thompson}, relying primarily on the NumPy~\autocite{numpy} and SciPy libraries~\autocite{scipy}, while the (simulation of the) QUCB algorithm was implemented as in explained in \cref{sec:qucb-implementation}, with the Qiskit library~\autocite{qiskit} for quantum computing support.

Remark that it is specifically the UCB1 of~\autocite{auer2002} that is implemented and that the digit is here omitted from the notation for brevity.
Similarly, what here is simply called QUCB is in the original paper called $\text{QUCB}_1$.
The Thompson sampling algorithm that is implemented follows the original paper ~\autocite{thompson1933}, with its uniform prior and Beta posterior distributions.

For fixed bandit instances, 100 simulations were run for each algorithm, while for Bayesian regrets 1000 parallels were run.
Simulating quantum algorithms is computationally expensive, in general exponentially hard, such that much higher numbers of simulations were not feasible for the QUCB algorithm and the time horizons considered.
To limit the scope and computational resources required, only Bernoulli rewards were considered, and in every case except one, only two arms were used.
How the algorithm handles more arms may be of some interest, but its principal advantage is its better dependence on the time horizon $T$, and it handles multiple arms the same was as the classical UCB algorithm, so there is no reason to expect any regret improvements as the number of arms increases.

Across all bandit simulations, a time horizon of $T=250,000$ was used.
This is indeed a large number, but still merely a quarter of what was tested in~\autocite{wan2022}.
The quantum algorithm presents no immediate advantage for smaller time horizons, so  a time horizon of some substance must be chosen to see its effects.
Specifically, due to its exponentially long quantum Monte Carlo periods, as seen in \cref{sec:wan2022}, the horizon must be large enough for the greater accuracy of the QMC estimates to outweigh the cost of the long periods.

As noted in~\autocite{wan2022}, setting the confidence parameter to a higher value than the theoretically desirable $1/T$ leads to better performance.
It was thus set to $0.01$ for all experiments.
Moreover, the constant $C_1$, which is only defined existentially, was arbitrarily set to $2$ across all experiments, as it was not clear how to choose it in a principled manner, and this value seemed able to reproduce the results of~\autocite{wan2022}.

\subsection{Fixed arms}
\label{sec:sim_fixed_arms}
First, the algorithms are tested on fixed bandit instances with two arms.
The mean of the first arm is set to $0.5$ and the mean of the second arm is set to $0.505$, an instance also tested in~\autocite{wan2022}.
The results are shown in \cref{fig:big2}, agreeing with the original paper; QUCB greatly outperforms UCB.
However, Thompson sampling which was not considered in~\autocite{wan2022}, is not that far behind.

Note the jagged and periodically completely flat behaviour of the QUCB algorithm regret.
This is due to the long QMC periods in which its quantum advantage is gained; it must repeatedly pull the same arm for the QMC estimates to be produced.
When the algorithm pulls the optimal arm, the change in regret is obviously zero.
Additionally, these periods get longer as the algorithm progresses, as the QMC estimates become more accurate.
The exponential lengthening of the QMC periods assure that such non-smooth and piecewise linear behaviour is to be expected.
Because of these long periods, there is not as many possible trajectories as with the classical algorithms, so the jaggedness persists despite averaging over many simulations.

\begin{figure}
    \centering
    \newcommand{\myoptions}{
        width=10cm,
        height=8cm,
        xlabel={Kiloturn},
        ylabel={Regret},
        legend entries={UCB, QUCB, Thompson},
        legend pos=north west,
        legend cell align=left,
        mystyle,
    }
    \subimport{figs}{big2}
    \caption[
        Regrets for two Bernoulli arms, with means 0.5 and 0.505.
    ]{
        Regrets for two Bernoulli arms, with means 0.5 and 0.505.
        The QUCB algorithm is clearly superior to UCB, but Thompson sampling is not far behind.
        A great time horizon of 250,000 turns is used.
    }
    \label{fig:big2}
\end{figure}

\subsubsection{Low and high probabilities}
Next, more extreme mean values of $0.01$ and $0.005$ with a reward gap of $0.005$ equal to the above, are tested.
\Cref{fig:low_prob_fix} contains the results for these simulations.
There, it can be seen that QUCB beats UCB thoroughly still, as both algorithms achieving similar regrets as in \cref{fig:big2}, but now Thompson sampling is clearly superior.


\begin{figure}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \newcommand{\myoptions}{
            width=10cm,
            height=8cm,
            xlabel={Kiloturn},
            ylabel={Regret},
            legend entries={UCB, QUCB, Thompson},
            legend pos=north west,
            legend cell align=left,
            mystyle,
        }
        \subimport{figs}{low_prob_fix}
        \caption{Two Bernoulli arms, means 0.01, 0.005.}
        \label{fig:low_prob_fix}
    \end{subfigure}
    \\[3ex]
    \begin{subfigure}{\textwidth}
        \centering
        \newcommand{\myoptions}{
            width=10cm,
            height=8cm,
            xlabel={Kiloturn},
            ylabel={Regret},
            legend entries={UCB, QUCB, Thompson},
            legend pos=north west,
            legend cell align=left,
            mystyle,
        }
        \subimport{figs}{high_prob}
        \caption{Two Bernoulli arms, means 0.99, 0.9905.}
        \label{fig:high_prob}
    \end{subfigure}
    \label{fig:low_high_prob}
    \caption[
        Regrets for two Bernoulli arms with more extreme means.
    ]{
        Regrets for two Bernoulli arms with more extreme means.
    }
\end{figure}

At these extreme values, it seems the gap must shrink for QUCB to be able to outperform Thompson sampling.
This is shown in \cref{fig:high_prob}, where the gap is reduced to $0.0005$,
Even so, the QUCB advantage is not as pronounced as in \cref{fig:big2}.

\subsubsection{Four arms}
As a final test, the number of arms is increased to four.
The results are plotted in \cref{fig:four_arms}.
Only cases with two arms were tested in the original paper, so this is a new test, further validating the correctness of the algorithm and its implementation.
The results are similar to the two-arm case, with QUCB outperforming UCB.
At these particular reward means, Thompson sampling performs very similarly to QUCB.
In general, QUCB provides no advantages or noteworthy changes from UCB with respect to the number of arms, so its behaviour should be expected to be similar as UCB when the number of arms is increased.

\begin{figure}
    \centering
    \newcommand{\myoptions}{
        width=10cm,
        height=8cm,
        xlabel={Kiloturn},
        ylabel={Regret},
        legend entries={UCB, QUCB, Thompson},
        legend pos=north west,
        legend cell align=left,
        mystyle,
    }
    \subimport{figs}{four_arms}
    \caption[
        Regrets for four arms, with means 0.5, 0.51, 0.52 and 0.53.
    ]
    {
        Regrets for four arms, with means 0.5, 0.51, 0.52 and 0.53.
    }
    \label{fig:four_arms}
\end{figure}

\clearpage
\subsection{Bayesian regret}
\label{sec:results_bayesian}
As described in \cref{sec:bayesian-optimality}, the Bayesian regret is the average regret over some prior.
What priors to choose is a topic for discussion, which will not be covered deeply in this section nor thesis in general.
It may not be the most relevant measure for which to optimise policies, as explained in \cref{sec:optimality}.
In any case, it provides a measure of robustness, measuring the performance over a range of possible instances.

\subsubsection{Uniform prior}
First, the simple case of two arms, whose means are independently drawn from a uniform distribution on the interval $[0, 1]$ will be considered.
The Bayesian regret for this case is on display in \cref{fig:random}.
All three were run on 1,000 instances sampled from the prior.
Having randomness also in the bandit instances motivated the use of a larger number of simulations than in the previous experiments.
The results shown are the averages over these instances.

It is obvious that the Thompson sampling algorithm performs best.
QUCB does outperform UCB, but not by as much as the previously considered cases and not in the first $\approx 30,000$ turns.

The lack of any quantum advantage is probably due to this prior generally yielding \enquote{easy} problems, where the optimal arm can be quickly identified.
In such cases, the initial overhead of the quantum algorithm appears not to be worth the effort.
QUCB with its current QMC implementation relies on a large number of initial samples to produce it supreme estimates, but with the uniform prior and only two arms, the expected difference of means is a third, so the optimal arm can often be identified after only a few turns with high certainty.
Nonetheless, after the rather wasteful inaugural period, QUCB does indeed produce a very flat regret curve; inspecting the log-log-plot in \cref{fig:random}, it may seem like the QUCB regret curve would lie below even Thompson sampling at some great and admittedly unrealistic number of turns, perhaps something around the order of $10^{9}$.



\begin{figure}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \newcommand{\myoptions}{
            width=10cm,
            height=8cm,
            xlabel={Kiloturn},
            ylabel={Regret},
            legend entries={UCB, QUCB, Thompson},
            legend pos=north west,
            legend cell align=left,
            mystyle,
            ymax = 150,
        }
        \subimport{figs}{uniform_prior.tex}
        \caption{Linear scale.}
    \end{subfigure}
    \\[3ex]
    \begin{subfigure}{\textwidth}
        \centering
        \newcommand{\myoptions}{
            width=10cm,
            height=8cm,
            xlabel={Turn},
            ylabel={Regret},
            legend entries={UCB, QUCB, Thompson},
            legend pos=north west,
            legend cell align=left,
            mystyle,
        }
        \subimport{figs}{uniform_prior_loglog.tex}
        \caption{Log-log scale.}
    \end{subfigure}
    \caption[
        Bayesian regret for two arms, independent and uniform priors.
    ]
    {
        Bayesian regret for two arms, independent and uniform priors.
        While Thompson sampling performs best, the log-log plot may indicate that QUCB could be better with a very large number of turns.
        Thompson sampling performs best, but it can appear as QUCB would be best at unreasonably great time horizons.
    }
    \label{fig:random}
\end{figure}


\subsubsection{Challenging prior}
One might argue that the uniform prior is too easy, and that the quantum advantage should be more apparent in a more challenging prior.
Firstly, for real-world Bernoulli bandits, there may be reasons to believe that the means would lie closer to the endpoints 0 and 1 than in the middle.
Secondly, for the problem to be interesting and warrant the use of clever quantum algorithms or even just any bandit theory, the means should be assumed close to each other.
Thus, to consider a more challenging prior, the following was chosen:
\begin{equation}
    \label{eq:challenging_prior}
    \begin{aligned}
        \mu_1               & \sim \text{B}(0.5, 0.5),                 \\
        \text{logit}(\mu_2) & \sim \text{N}(\text{logit}(\mu_1), 0.1),
    \end{aligned}
\end{equation}
where the logit is given by
\begin{equation}
    \label{eq:logit}
    \text{logit}(\mu) = \log(\mu/(1-\mu)).
\end{equation}
This prior is displayed in \cref{fig:priors}.

The logit is used to ensure that the means are in the interval $[0, 1]$.
It is particularly well-suited for interpreting the means of Bernoulli bandits due to its ability to capture meaningful differences between probabilities. For example, on the logit scale, the distance between 0.001 and 0.101 is much greater than that between 0.4 and 0.5.
Its symmetry around zero and coverage of the entire real number line allow for a comprehensive representation of the reward means.

% \begin{figure}
%     \centering
%     \begin{subfigure}{\textwidth}
%         \centering
%         \begin{tikzpicture}
%             \centering
%             \begin{axis}[
%                     width=10cm,
%                     height=8cm,
%                     enlargelimits=false,
%                     axis on top,
%                     xlabel={$\mu_1$},
%                     ylabel={$\mu_2 - \mu_1$},
%                     yticklabel style={
%                             /pgf/number format/fixed,
%                             /pgf/number format/precision=3
%                         },
%                     scaled y ticks=false,
%                     colorbar,
%                     colormap/plasma,
%                     point meta min=0,
%                     point meta max=47.6,
%                     view={0}{90},
%                 ]
%                 \addplot graphics [
%                         xmin=0,
%                         xmax=1,
%                         ymin=-0.1,
%                         ymax=0.1,
%                     ] {figs/priors/prior1};
%             \end{axis}
%         \end{tikzpicture}
%         \label{fig:challenging_prior}
%         \caption[
%             \Cref{eq:challenging_prior}.
%         ]
%         {
%             \Cref{eq:challenging_prior}.
%         }
%     \end{subfigure}
%     \begin{subfigure}{\textwidth}
%         \centering
%         \begin{tikzpicture}
%             \centering
%             \begin{axis}[
%                     width=10cm,
%                     height=8cm,
%                     enlargelimits=false,
%                     axis on top,
%                     xlabel={$\mu_1$},
%                     ylabel={$\mu_2 - \mu_1$},
%                     yticklabel style={
%                             /pgf/number format/fixed,
%                             /pgf/number format/precision=3
%                         },
%                     scaled y ticks=false,
%                     colorbar,
%                     colormap/plasma,
%                     point meta min=0,
%                     point meta max=149.6,
%                     view={0}{90},
%                 ]
%                 \addplot graphics [
%                         xmin=0,
%                         xmax=1,
%                         ymin=-0.02,
%                         ymax=0.02,
%                     ] {figs/priors/prior2};
%             \end{axis}
%         \end{tikzpicture}
%         \label{fig:more_challenging_prior}
%         \caption{\Cref{eq:more_challenging_prior}.}
%     \end{subfigure}
%     \label{fig:priors}
%     \caption[
%         Priors used in the Bayesian regret experiments.
%     ]
%     {
%         Priors used in the Bayesian regret experiments.
%         The joint distribution of the first arm and the difference between the means is shown.
%         At these close arm means, any asymmetry differences are imperceptible; were the standard deviation greater, the difference would tend more upwards at low values for arm 1 and vice versa.
%         Note that the density in (a) diverges at $(\mu_1, \mu_2) = (0, 0)$ and $(1, 1)$.
%         Values above the colour bar maximum are therefore clipped.
%     }
% \end{figure}

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{groupplot}[
                width=10cm,
                height=8cm,
                enlargelimits=false,
                axis on top,
                xlabel={$\mu_1$},
                ylabel={$\mu_2 - \mu_1$},
                yticklabel style={
                        /pgf/number format/fixed,
                        /pgf/number format/precision=3
                    },
                scaled y ticks=false,
                colorbar,
                colormap/plasma,
                point meta min=0,
                view={0}{90},
                group style={
                        group size=1 by 2,
                        vertical sep=2cm,
                    },
            ]
            \nextgroupplot[
                title={\Cref{eq:challenging_prior}},
                xmin=0,
                xmax=1,
                ymin=-0.1,
                ymax=0.1,
                point meta max=47.6,
            ]
            \addplot graphics [
                    xmin=0,
                    xmax=1,
                    ymin=-0.1,
                    ymax=0.1,
                ] {figs/priors/prior1};

            \nextgroupplot[
                title={\Cref{eq:more_challenging_prior}},
                xmin=0,
                xmax=1,
                ymin=-0.02,
                ymax=0.02,
                point meta max=149.6,
            ]
            \addplot graphics [
                    xmin=0,
                    xmax=1,
                    ymin=-0.02,
                    ymax=0.02,
                ] {figs/priors/prior2};
        \end{groupplot}
    \end{tikzpicture}
    \caption[
        Priors used in Bayesian regret experiments.
    ]
    {
        Priors used in Bayesian regret experiments.
        The joint distributions of the first arm and the difference between the means are shown.
        At these close arm means, any asymmetry differences are imperceptible; were the standard deviation greater, the difference would tend more upwards at low values for arm 1 and vice versa.
        Note that the density in \cref{eq:challenging_prior} diverges at $(\mu_1, \mu_2) = (0, 0)$ and $(1, 1)$.
        Values above the colour bar maximum are therefore clipped in the upper image.
    }
    \label{fig:priors}
\end{figure}



Running a successful 1,000 simulations with this prior, the regrets visualised in \cref{fig:random2} were obtained.
At the final 250,000th turn, the QUCB and Thompson sampling algorithms have virtually equal regrets.
QUCB lags behind in the beginning, but its regret curve appears flatter towards the end, and it is likely that it would beat Thompson sampling in the long run.
The UCB algorithm, on the other hand, is as before clearly outperformed by both QUCB and Thompson sampling.

\subsubsection{More challenging prior}
As the above prior proved to still too easy to demonstrate quantum advantage, a third was chosen, catering even more to QUCB's strengths discovered in \cref{sec:sim_fixed_arms}, id est, where the arm means are close, and their means are centred around one half.
The prior was constructed similarly to the one in \cref{eq:challenging_prior}, but with different parameters, namely:
\begin{equation}
    \label{eq:more_challenging_prior}
    \begin{aligned}
        \mu_1               & \sim \text{B}(2, 2),                      \\
        \text{logit}(\mu_2) & \sim \text{N}(\text{logit}(\mu_1), 0.02),
    \end{aligned}
\end{equation}
as is rendered in \cref{fig:priors}.

This simulation was also run for 1,000 parallels.
As is seen in \cref{fig:random3}, QUCB is reclaims superiority, while Thompson sampling still clearly outperforms UCB.
It is clear that this prior produces so challenging instances, that the advantage over pure exploration is not as apparent as in the previous priors, but more akin to the first considered fixed instances in \cref{sec:sim_fixed_arms}, where the QUCB advantage was initially observed\footnote{Viz. \cref{fig:big2,fig:high_prob}.}.


\begin{figure}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \newcommand{\myoptions}{
            width=10cm,
            height=8cm,
            xlabel={Kiloturn},
            ylabel={Regret},
            legend entries={UCB, QUCB, Thompson},
            legend pos=north west,
            legend cell align=left,
            mystyle,
            ymax = 400,
        }
        \subimport{figs}{challenging_prior.tex}
        \caption{
            Prior as in \cref{eq:challenging_prior}.
        }
        \label{fig:random2}
    \end{subfigure}
    \\[3ex]
    \begin{subfigure}{\textwidth}
        \centering
        \newcommand{\myoptions}{
            width=10cm,
            height=8cm,
            xlabel={Kiloturn},
            ylabel={Regret},
            legend entries={UCB, QUCB, Thompson},
            legend pos=north west,
            legend cell align=left,
            mystyle,
        }
        \subimport{figs}{more_challenging_prior.tex}
        \caption{
            Prior as in \cref{eq:more_challenging_prior}.
        }
        \label{fig:random3}
    \end{subfigure}
    \caption[
        Bayesian regret for two arms, challenging priors.
    ]
    {
        Bayesian regret for two arms, challenging priors,
        The lower figure has the means closer to the $1/2$ and even higher correlation between the means, which is more favourable to QUCB.
    }
    \label{fig:random_challenging}
\end{figure}

\subsubsection{Regret distributions}
In \cref{fig:histograms_random}, the regrets at the final turn for the three algorithms are shown for the three priors that were tested.
The distributions are clearly wide, but with 1,000 samples, the conclusions drawn in the previous sections are nevertheless significant.

For the uniform prior, Thompson sampling is unquestionably supreme, while for the prior of \cref{eq:challenging_prior}, QUCB and Thompson achieve a similar average regret, but with QUCB's distribution being more concentrated.
It seems that even the classical UCB algorithm has a better mode than QUCB, but with its heavy tail it is still outperformed by QUCB on average.
Across all three histograms, it appears as QUCB is more consistent in its performance, being less dependent on the random instances that are generated, while Thompson sampling, though better on many instances, suffers from outliers with very high regret.
QUCB seemingly produces equal regrets independent of the prior, while the two classical algorithms perform worse on the more challenging priors.
This could perhaps be explained with its logarithmic instance-independent regret bound as shown in \cref{sec:wan_proof}.
Classically, such bounds are at best proportional to the square root of the Horizon.
With its early and expensive exploration period, the QUCB algorithm is able to identify the best arm within the horizons considered here, seemingly independent of the difficulty of the instance.

The classical UCB algorithm appears to have even more spread in its regret distribution than Thompson sampling, and simply worse performance overall.
This is to be expected, as it does not achieve the same guarantees as Thompson sampling, as discussed in \cref{chap:bandits}.


% \begin{figure}
%     \centering
%     \begin{subfigure}{\textwidth}
%         \centering
%         \begin{tikzpicture}
%             \begin{axis}[
%                     width=10 cm,
%                     height=5 cm,
%                     ybar,
%                     xlabel={Regret},
%                     ylabel={No. of occurrences},
%                     xmin = 0,
%                     xmax = 400,
%                     ymin = 0,
%                     grid = major,
%                 ]
%                 \pgfplotstableread[col sep=comma]{../code/wan/results/random/final_turn_regerts.dat}\datatable
%                 \addplot+ [hist={bins=60}, red, opacity=0.5]
%                 table [y index=2, col sep=comma]
%                 \datatable;

%                 \addplot+ [hist={bins=60}, blue, opacity=0.5]
%                 table [y index=0, col sep=comma]
%                 \datatable;

%                 \addplot+ [hist={bins=60}, green, opacity=0.5]
%                 table [y index=1, col sep=comma]
%                 \datatable;

%                 \legend{UCB, QUCB, Thompson};
%             \end{axis}
%         \end{tikzpicture}
%         \caption{Uniform prior.}
%     \end{subfigure}

%     \begin{subfigure}{\textwidth}
%         \centering
%         \begin{tikzpicture}
%             \begin{axis}[
%                     width=10 cm,
%                     height=5 cm,
%                     ybar,
%                     xlabel={Regret},
%                     ylabel={No. of occurrences},
%                     xmin = 0,
%                     xmax = 600,
%                     ymin = 0,
%                     grid = major,
%                 ]
%                 \pgfplotstableread[col sep=comma]{../code/wan/results/random2/final_turn_regerts.dat}\datatable
%                 \addplot+ [hist={bins=60}, red, opacity=0.5]
%                 table [y index=2, col sep=comma]
%                 \datatable;

%                 \addplot+ [hist={bins=60}, blue, opacity=0.5]
%                 table [y index=0, col sep=comma]
%                 \datatable;

%                 \addplot+ [hist={bins=60}, green, opacity=0.5]
%                 table [y index=1, col sep=comma]
%                 \datatable;

%                 \legend{UCB, QUCB, Thompson};

%             \end{axis}
%         \end{tikzpicture}
%         \caption{Prior as in \cref{eq:challenging_prior}.}
%     \end{subfigure}


%     \begin{subfigure}{\textwidth}
%         \centering
%         \begin{tikzpicture}
%             \begin{axis}[
%                     width=10 cm,
%                     height=5 cm,
%                     ybar,
%                     xlabel={Regret},
%                     ylabel={No. of occurrences},
%                     xmin = 0,
%                     xmax = 600,
%                     ymin = 0,
%                     grid = major,
%                 ]
%                 \pgfplotstableread[col sep=comma]{../code/wan/results/random3/final_turn_regerts.dat}\datatable
%                 \addplot+ [hist={bins=60}, red, opacity=0.5]
%                 table [y index=2, col sep=comma]
%                 \datatable;

%                 \addplot+ [hist={bins=60}, blue, opacity=0.5]
%                 table [y index=0, col sep=comma]
%                 \datatable;

%                 \addplot+ [hist={bins=60}, green, opacity=0.5]
%                 table [y index=1, col sep=comma]
%                 \datatable;

%                 \legend{UCB, QUCB, Thompson};

%             \end{axis}
%         \end{tikzpicture}
%         \caption{Prior as in \cref{eq:more_challenging_prior}.}
%     \end{subfigure}

%     \caption[
%         Histograms of final turn regret for the three priors considered.
%     ]
%     {
%         Histograms of final turn regret for the three priors considered.
%         Note that the rightmost bin is open-ended, including all values greater than the highest regret value plotted.
%     }
%     \label{fig:histograms_random}
% \end{figure}


\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{groupplot}[
                ybar,
                xlabel={Regret},
                ylabel={No. of occurrences},
                xmin = 0,
                ymin = 0,
                grid = major,
                group style={
                        group size=1 by 3,
                        vertical sep=2.5cm,
                    },
            ]
            \nextgroupplot[
                title={Uniform prior},
                width=10 cm,
                height=5 cm,
                xmax = 600,
                % legend style={at={(0.5,-0.2)},anchor=north},
            ]
            \pgfplotstableread[col sep=comma]{../code/wan/results/random/final_turn_regerts.dat}\datatable
            \addplot+ [hist={bins=60}, red, opacity=0.5]
            table [y index=2, col sep=comma]
            \datatable;

            \addplot+ [hist={bins=60}, blue, opacity=0.5]
            table [y index=0, col sep=comma]
            \datatable;

            \addplot+ [hist={bins=60}, green, opacity=0.5]
            table [y index=1, col sep=comma]
            \datatable;

            \legend{UCB, QUCB, Thompson};

            \nextgroupplot[
                title={Prior as in \cref{eq:challenging_prior}},
                width=10 cm,
                height=5 cm,
                xmax = 600,
                % legend style={at={(0.5,-0.2)},anchor=north},
            ]
            \pgfplotstableread[col sep=comma]{../code/wan/results/random2/final_turn_regerts.dat}\datatable
            \addplot+ [hist={bins=60}, red, opacity=0.5]
            table [y index=2, col sep=comma]
            \datatable;

            \addplot+ [hist={bins=60}, blue, opacity=0.5]
            table [y index=0, col sep=comma]
            \datatable;

            \addplot+ [hist={bins=60}, green, opacity=0.5]
            table [y index=1, col sep=comma]
            \datatable;

            \legend{UCB, QUCB, Thompson};

            \nextgroupplot[
                title={Prior as in \cref{eq:more_challenging_prior}},
                width=10 cm,
                height=5 cm,
                xmax = 600,
                % legend style={at={(0.5,-0.2)},anchor=north},
            ]
            \pgfplotstableread[col sep=comma]{../code/wan/results/random3/final_turn_regerts.dat}\datatable
            \addplot+ [hist={bins=60}, red, opacity=0.5]
            table [y index=2, col sep=comma]
            \datatable;

            \addplot+ [hist={bins=60}, blue, opacity=0.5]
            table [y index=0, col sep=comma]
            \datatable;

            \addplot+ [hist={bins=60}, green, opacity=0.5]
            table [y index=1, col sep=comma]
            \datatable;

            \legend{UCB, QUCB, Thompson};

        \end{groupplot}
    \end{tikzpicture}

    \caption[
        Histograms of final turn regret for the three priors considered.
    ]
    {
        Histograms of final turn regret for the three priors considered.
        Note that the rightmost bins are open-ended, including all values greater than the highest regret value indicated.
    }
    \label{fig:histograms_random}
\end{figure}
