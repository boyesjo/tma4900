\section{Bayesian regret}
\label{sec:results_bayesian}
As described in \cref{sec:bayesian-optimality}, the Bayesian regret is the average regret over some set prior.
What priors to choose is a topic for discussion, which will not be covered deeply here.

\subsection{Uniform prior}
First, the simple case of two arms, whose means are independently drawn from a uniform distribution on the interval $[0, 1]$ will be considered.
The Bayesian regret for this case is on display in \cref{fig:random}.
All three were run on 294 instances sampled from the prior\footnotemark, and the results are averaged over these instances.

\footnotetext{
    During the 295th run, the program crashed due issues relating to disk usage permissions.
}

It is obvious that the Thompson sampling algorithm performs best.
QUCB does outperform UCB, but not by as much as the previously considered cases and only after some time.

The lack of any quantum advantage is probably due to this prior generally yielding \enquote{easy} problems, where the optimal arm can be quickly identified.
In such cases, the initial overhead of the quantum algorithm appears not to be worth the effort.
Nonetheless, after the rather wasteful inaugural period, QUCB does indeed produce a very flat regret curse; when looking at the log-log-plot in \cref{fig:random}, it may seem like the QUCB regret will be lower than even Thompson sampling for some great and admittedly unrealistic number of turns.



\begin{figure}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \subimport{figs}{uniform_prior.tex}
        \caption{Linear scale.}
    \end{subfigure}
    \\[3ex]
    \begin{subfigure}{\textwidth}
        \centering
        \subimport{figs}{uniform_prior_loglog.tex}
        \caption{Log-log scale.}
    \end{subfigure}
    \caption[
        Bayesian regret for two arms, independent and uniform priors.
    ]
    {
        Bayesian regret for two arms, independent and uniform priors.
        While Thompson sampling performs best, the log-log plot may indicate that QUCB could be better with a very large number of turns.
        Thompson sampling performs best, but it can appear as QUCB would be best at unreasonably great time horizons.
    }
    \label{fig:random}
\end{figure}


\subsection{Challenging prior}
One might argue that the uniform prior is too easy, and that the quantum advantage should be more apparent in a more challenging prior.
Firstly, for real-world Bernoulli bandits, there are reasons to believe that the means would lie closer to the endpoints 0 and 1 than in the middle.
Secondly, for the problem to be interesting and warrant the use of clever quantum algorithms or even just any bandit theory, the means should be close to each other.
Thus, the following prior was chosen:
\begin{equation}
    \label{eq:challenging_prior}
    \begin{aligned}
        \mu_1               & \sim \text{B}(0.5, 0.5),                 \\
        \text{logit}(\mu_2) & \sim \text{N}(\text{logit}(\mu_1), 0.1),
    \end{aligned}
\end{equation}
where $\text{logit}(\mu) = \log(\mu/(1-\mu))$.

Running a successful 1000 simulations with this prior, the regrets visualised in \cref{fig:random2} were obtained.
At the final 250,000th turn, the QUCB and Thompson sampling algorithms have virtually equal regrets.
QUCB lags behind in the beginning, but its regret curve appears flatter towards the end, and it is likely that it would beat Thompson sampling in the long run.
The UCB algorithm, on the other hand, is as before clearly outperformed by both QUCB and Thompson sampling.

\subsection{More challenging prior}
As the above prior proved to still too easy to demonstrate quantum advantage, a third was chosen, catering even more to QUCB's strengths discovered in \cref{sec:sim_fixed_arms}, id est having close means and means centred around one half.
The prior was constructed similarly to the one in \cref{eq:challenging_prior}, but with different parameters, namely:
\begin{equation}
    \label{eq:more_challenging_prior}
    \begin{aligned}
        \mu_1               & \sim \text{B}(2, 2),                      \\
        \text{logit}(\mu_2) & \sim \text{N}(\text{logit}(\mu_1), 0.02),
    \end{aligned}
\end{equation}

This simulation was run for 966 parallels before the computation server got tired.
As is seen in \cref{fig:random3}, QUCB is reclaims superiority, while Thompson sampling still clearly outperforms UCB.


\begin{figure}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \subimport{figs}{challenging_prior.tex}
        \caption{
            Prior as in \cref{eq:challenging_prior}.
        }
        \label{fig:random2}
    \end{subfigure}
    \\[3ex]
    \begin{subfigure}{\textwidth}
        \centering
        \subimport{figs}{more_challenging_prior.tex}
        \caption{
            Prior as in \cref{eq:more_challenging_prior}.
        }
        \label{fig:random3}
    \end{subfigure}
    \caption[
        Bayesian regret for two arms, challenging priors.
    ]
    {
        Bayesian regret for two arms, challenging priors,
        The lower figure has the means closer to the $1/2$ and even higher correlation between the means, which is more favourable to QUCB.
    }
    \label{fig:random_challenging}
\end{figure}