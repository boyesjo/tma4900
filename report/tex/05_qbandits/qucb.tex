\section{Oracles as bandit arms}
A way to quantise the bandit problem is to assign to each arm a quantum oracle.
For each arm $a \in \mathcal{A}$, a bandit oracle can be defined as
\begin{equation}
    \mathcal{O}_a: \ket{0}\otimes\ket{0} \mapsto \sum_{\omega \in \Omega} \left(\sqrt{P_a(\omega)} \ket{\omega} \otimes \ket{X_a(\omega)} \right),
    \label{eq:wan_oracle}
\end{equation}
where $\omega$ is some sample space on which $X_a$ is a random variable with probability measure $P_a$.
Applying the oracle to the state $\ket{0}$ produces a superposition of all possible outcomes of the random variable $X_a$, such that measuring the second register will produce a sample from $X_a$.
In this way, this quantum version of the bandit problem can be reduced to the classical case, but by maintaining the superposition, quantum advantages can be gained.

As with classical arms, the agent decides for each step in the bandit problem which oracle to invoke, trying to minimise the cumulative regret, where the means here are defined as
\begin{equation}
    \begin{aligned}
        \mu_a
         & = \sum_{\omega \in \Omega} P_a(\omega) X_a(\omega)                     \\
         & = \bra{00} \mathcal{O}_a^\dagger (I \otimes Z) \mathcal{O}_a) \ket{00} \\
    \end{aligned}
\end{equation}
In \autocite{wan2022}, an algorithm for bounded-value arms achieving $O(n \log T)$ regret was proposed, $n$ being the number of arms.
For bounded variances, the regret is $O(n \ \text{poly}(\log T))$, which is still substantially better than $\Omega(\sqrt{nT})$ minimax regret for classical bandits.

The algorithm proposed is essentially a UCB-like algorithm, where QMC (as described in \cref{sec:qmc}) is used to estimate means more efficiently.
Because QMC estimates are only produced after a set number of quantum queries, the algorithm must cleverly decide for how many steps to pull each arm in addition to which arm to pull, before running a QMC session.

As listed in \cref{alg:qucb1}, the algorithm first runs a preliminary phase where the means are estimated using QMC with a fixed number of samples, after which it iteratively pulls the arms with the highest confidence bounds, after which the confidence bound are halved and the number of QMC samples to be used for that arm is doubled.
A confidence parameter $\delta$ is used to determine the number of QMC samples to use, satisfying $\lvert\hat{\mu}_i - \mu_i\rvert \leq \text{UCB}_i$ with probability $1-\delta$.
The constant $C_1>1$ is only described existentially to give an upper bound to the number of QMC queries needed, coming from the big-O notation used to describe QMC convergence.
How it should be set for implementation of the algorithm is not described in the paper.

\begin{algorithm}
    \caption{QUCB1 as proposed in \autocite{wan2022}}
    \label{alg:qucb1}
    \begin{algorithmic}[1]
        \Require Set of arms $\mathcal{A}$, $\mathcal{O}_i$ as in \cref{eq:wan_oracle}, $T$ horizon, $0 < \delta \ll 1$
        \For {$a \in \mathcal{A}$}
        \State $\text{UCB}_a \gets 1$
        \State $N_a \gets (C_1/\text{UCB}_a) \log(1/\delta)$
        \State Estimate $\mu_a$ using QMC with $N_a$ samples
        \EndFor
        \While{Total number of queries to the oracles is less than $T$}
        \State $a \gets \argmax_a (\hat\mu_a + \text{UCB}_a)$
        \State $\text{UCB}_a \gets \text{UCB}_a /2$
        \State $N_a \gets (C_1/\text{UCB}_a) \log(1/\delta)$
        \State Update estimate of $\mu_a$ using QMC with $N_a$ samples
        \EndWhile
    \end{algorithmic}
\end{algorithm}
