\section{Quantum upper confidence bounds}
\label{sec:wan2022}
A way to quantise the bandit problem is to assign to each arm a quantum oracle.
For each arm $a \in \mathcal{A}$, a bandit oracle can be defined as
\begin{equation}
    \mathcal{O}_a: \ket{0}\otimes\ket{0} \mapsto \sum_{\omega \in \Omega} \left(\sqrt{P_a(\omega)} \ket{\omega} \otimes \ket{X_a(\omega)} \right),
    \label{eq:wan_oracle}
\end{equation}
where $\omega$ is some sample space on which $X_a$ is a random variable with probability measure $P_a$.
Applying the oracle to the state $\ket{0}$ produces a superposition of all possible outcomes of the random variable $X_a$, such that measuring the second register will produce a sample from $X_a$.
In this way, this quantum version of the bandit problem can be reduced to the classical case, but by maintaining the superposition, quantum advantages can be gained.

As with classical arms, the agent decides for each step in the bandit problem which oracle to invoke, trying to minimise the cumulative regret, where the means here are defined as
\begin{equation}
    \begin{aligned}
        \mu_a
         & = \sum_{\omega \in \Omega} P_a(\omega) X_a(\omega)                     \\
         & = \bra{00} \mathcal{O}_a^\dagger (I \otimes Z) \mathcal{O}_a) \ket{00} \\
    \end{aligned}
\end{equation}
In~\autocite{wan2022}, an algorithm for bounded-value arms achieving $O(n \log T)$ regret was proposed, $n$ being the number of arms.
For bounded variances, the regret is $O(n \ \text{poly}(\log T))$, which is still substantially better than $\Omega(\sqrt{nT})$ minimax regret for classical bandits.

The algorithm proposed is essentially a UCB-like algorithm, where QMC (as described in \cref{sec:qmc}) is used to estimate means more efficiently.
Because QMC estimates are only produced after a set number of quantum queries, the algorithm must cleverly decide for how many steps to pull each arm in addition to which arm to pull, before running a QMC session.

As listed in \cref{alg:qucb1}, the algorithm first runs a preliminary phase where the means are estimated using QMC with a fixed number of samples, after which it iteratively pulls the arms with the highest confidence bounds, after which the confidence bound are halved and the number of QMC samples to be used for that arm is doubled.
A confidence parameter $\delta$ is used to determine the number of QMC samples to use, satisfying $\lvert\hat{\mu}_i - \mu_i\rvert \leq \text{UCB}_i$ with probability $1-\delta$.
The constant $C_1>1$ is only described existentially to give an upper bound to the number of QMC queries needed, coming from the big-O notation used to describe QMC convergence.
How it should be set for implementation of the algorithm is not described in the paper.

% \begin{algorithm}
%     \caption{QUCB1 as proposed in~\autocite{wan2022}}
%     \label{alg:qucb1}
%     \begin{algorithmic}[1]
%         \Require Set of arms $\mathcal{A}$, $\mathcal{O}_i$ as in \cref{eq:wan_oracle}, $T$ horizon, $0 < \delta \ll 1$
%         \For {$a \in \mathcal{A}$}
%         \State $\text{UCB}_a \gets 1$
%         \State $N_a \gets (C_1/\text{UCB}_a) \log(1/\delta)$
%         \State Estimate $\mu_a$ using QMC with $N_a$ samples
%         \EndFor
%         \While{Total number of queries to the oracles is less than $T$}
%         \State $a \gets \argmax_a (\hat\mu_a + \text{UCB}_a)$
%         \State $\text{UCB}_a \gets \text{UCB}_a /2$
%         \State $N_a \gets (C_1/\text{UCB}_a) \log(1/\delta)$
%         \State Update estimate of $\mu_a$ using QMC with $N_a$ samples
%         \EndWhile
%     \end{algorithmic}
% \end{algorithm}

\begin{algorithm}
    \SetAlgoLined
    \caption{QUCB1}
    \label{alg:qucb1}
    \KwIn{Set of arms $\mathcal{A}$, $\mathcal{O}_i$ as in \cref{eq:wan_oracle}, $T$ horizon, $0 < \delta \ll 1$}
    \For {$a \in \mathcal{A}$}{
        $\text{UCB}_a \gets 1$\;
        $N_a \gets (C_1/\text{UCB}_a) \log(1/\delta)$\;
        Estimate $\mu_a$ using QMC with $N_a$ samples\;
    }
    \While{Total number of queries to the oracles is less than $T$}{
        $a \gets \argmax_a (\hat\mu_a + \text{UCB}_a)$\;
        $\text{UCB}_a \gets \text{UCB}_a /2$\;
        $N_a \gets (C_1/\text{UCB}_a) \log(1/\delta)$\;
        Update estimate of $\mu_a$ using QMC with $N_a$ samples\;
    }
\end{algorithm}

\subsection{Proof of logarithmic regret}
Recall that for variables in $Y \in [0, 1]$ producible by quantum algorithms, QMC can estimate $\mathbb{E}[Y]$ with error $\lvert\hat{\mu} - \mu\rvert \leq \epsilon$ with probability $1-\delta$ using $\frac{C_1}{\epsilon} \log \frac{1}{\delta}$ queries or less to the oracle or its adjoint, for some universal constant $C_1>1$.
That means that for each $a$,
\begin{equation}
    \lvert\hat{\mu}_a - \mu_a\rvert \leq \text{UCB}_a
    \quad \text{with probability} \quad
    1 - \delta,
    \label{eq:wan_qmc}
\end{equation}
for each QMC session in the algorithm.

Let $S_a$ be the set of stages where arm $a$ is pulled in the while-block of the algorithm, and let its cardinality be $K_a = |S_a|$.
Then, each arm is pulled $(2^{K_a + 1} - 1)C_1 \log \frac1\delta$ in the second phase.
With the preliminary phase, the total number of queries is
\begin{equation}
    C_1 \log \frac{1}{\delta} \sum_{a \in \mathcal{A}} 2^{K_a + 1} = T.
\end{equation}

Further, using Jensen's inequality,
\begin{equation}
    \sum_{a \in \mathcal{A}} 2^{K_a + 1} \geq k 2^{1/k \sum_{a \in \mathcal{A}} (K_a + 1)},
\end{equation}
it follows that
\begin{equation}
    \sum_{a \in \mathcal{A}} K_a
    \leq
    k \log_2 \left(\frac{T}{k C_1 \log \frac{1}{\delta}}\right) -k,
\end{equation}
which considering the first $k$ rounds, gives that the total number of QMC sessions is
\begin{equation}
    N_{\text{QMC}} \leq k \log_2 \left(\frac{T}{k C_1 \log \frac{1}{\delta}}\right).
\end{equation}

The probability of all QMC queries satisfying the error bound of \cref{eq:wan_qmc} is
\begin{equation}
    \begin{aligned}
        1 - \left(\bigcup_{i = 1}^{N_{\text{QMC}}} P(\text{Query } i \text{ fail}) \right)
         & \leq
        1 - \sum_{i = 1}^{N_{\text{QMC}}} P(\text{Query } i \text{ fail})             \\
         & \leq
        1 - \sum_{i = 1}^{N_{\text{QMC}}} \delta                                      \\
         & =
        1 - N_{\text{QMC}} \delta                                                     \\
         & \leq k \log_2 \left(\frac{T}{k C_1 \log \frac{1}{\delta}}\right) \ \delta.
    \end{aligned}
\end{equation}
Denote this event by $E$.
For the arm $a$ chosen in the arguments of the maxima at line 6 of the algorithm,
\begin{equation}
    \hat\mu_a + \text{UCB}_a \geq \hat\mu^* + \text{UCB}^*,
\end{equation}
and given $E$, it generally holds that
\begin{equation}
    \hat\mu \leq \mu + \text{UCB}
    \quad \text{and} \quad
    \mu \leq \hat\mu + \text{UCB}.
\end{equation}
Hence, the suboptimality gap of arm $a$ is bounded by
\begin{equation}
    \begin{aligned}
        \Delta_a & := \mu^* - \mu_a                                             \\
                 & \leq (\hat\mu^* + \text{UCB}^*) - (\hat\mu_a - \text{UCB}_a) \\
                 & \leq (\hat\mu_a + \text{UCB}_a) - (\hat\mu_a - \text{UCB}_a) \\
                 & = 2 \text{UCB}_a.
    \end{aligned}
\end{equation}
Notably, this holds regardless of what stage of the algorithm the arm is pulled in, so the last, most precise estimate of $\mu_a$ is used, wherein $\text{UCB}_a = 2^{1 - K_a}$.
Consequently, the regret contribution of arm $a$ is bounded by
\begin{equation}
    \begin{aligned}
        T_a \Delta_a & \leq 2 T_a \text{UCB}_a.                            \\
                     & = 2 (2^{K_a + 1} C_1 \log \frac1\delta) 2^{1 - K_a} \\
                     & = 2^3 C_1 \log \frac1\delta.
    \end{aligned}
\end{equation}
Given $E$, it is hence clear that
\begin{equation}
    \begin{aligned}
        \sum_{a \in \mathcal{A}} T_a \Delta_a  \leq 8 (k-1) C_1 \log \frac1\delta.
    \end{aligned}
\end{equation}

In the case where $E$ does not occur, the regret contribution can be bounded by
\begin{equation}
    \begin{aligned}
        \sum_{a \in \mathcal{A}} T_a \Delta_a \leq T \max_{a\in \mathcal{A}} \Delta_a \leq T,
    \end{aligned}
\end{equation}
as the arms are assumed to be Bernoulli.

The regret can hence be bounded by
\begin{equation}
    \begin{aligned}
        R_T
         & =
        \mathbb{E}\left[ \sum_{a \in \mathcal{A}} T_a \Delta_a \right]
        \\
         & =
        \mathbb{E}\left[ \mathbb{E}\left[ \sum_{a \in \mathcal{A}} T_a \Delta_a \ \middle| \ E \right] \right]
        \\
         & = P(E) \mathbb{E}\left[ \sum_{a \in \mathcal{A}} T_a \Delta_a \ \middle| \ E \right] + P(\neg E) \mathbb{E}\left[ \sum_{a \in \mathcal{A}} T_a \Delta_a \ \middle| \ \neg E \right]
        \\
         & \leq
        (1 - P(\neg E)) \left( 8(k-1)C_1 \log \frac1\delta \right)
        + P(\neg E) T
        \\
         & \leq
        8(k-1)C_1 \log \frac1\delta + P(\neg E) T.
        \\
         & \leq
        8(k-1)C_1 \log \frac1\delta + k\delta \log_2 \left(\frac{T}{kC_1 \log \frac1\delta}\right) T.
    \end{aligned}
\end{equation}
With this, setting $\delta = 1/T$, it is obtained that
\begin{equation}
    \begin{aligned}
        R_T
         & \leq
        8(k-1)C_1 \log \frac1\delta + k \log_2 \left(\frac{T}{kC_1 \log \frac1\delta}\right)
        \\
         & \leq
        8(k-1)C_1 \log T + k \log_2 \left(\frac{T}{kC_1 \log T}\right)
        \\
         & \leq
        8(k-1)C_1 \log_2 T + k \log_2 T
        \\
         & =
        (8(k-1)C_1 + k) \log_2 T
        \\
         & =
        O(k \log T)
    \end{aligned}
\end{equation}
as desired.

\subsection{Implementing quantum upper confidence bounds}
To translate \cref{alg:qucb1} into something that can be either run on a quantum computer or simulated on a classical computer, the arm-oracles need to be made available and QMC needs to be implemented.

\subsubsection{Arm-oracles}
The oracles of \cref{eq:wan_oracle} can be implemented as quantum gates by first constructing their matrix representation.
With Bernoulli variables and considering the simplest case of $\Omega = \{0, 1\}$ and associating only $0 \in \Omega$ with the reward, the first row of the matrix representation of the oracle is
\begin{equation}
    \sqrt{p} \ket{0} \ket{1} + \sqrt{1-p} \ket{1} \ket{0}
    =
    (0, 0, \sqrt{p}, \sqrt{1-p}).
\end{equation}
They are, however, not well-defined unitary operators, leaving several rows open for free choice.
These can be easily filled by using Gram-Schmidt orthogonalisation on the remaining rows.
More explicit solutions are of course possible, but these become more intricate with different reward distributions and $\Omega$.

In result, the oracle initialisation can be implemented as is listed in \cref{alg:qucb_oracle}, which is easily done in Qiskit.

\begin{algorithm}
    \SetAlgoLined
    \KwIn{Arm probability $p$}
    \KwOut{Quantum circuit}
    Initialise first row $(0, 0, \sqrt{p}, \sqrt{1-p})$ \;
    Complete matrix using Gram-Schmidt orthogonalisation \;
    \Return Quantum circuit implementing matrix
    \caption{QUCB oracle initialisation for a Bernoulli arm}
    \label{alg:qucb_oracle}
\end{algorithm}

\subsubsection{QMC}
Thankfully, amplitude estimation is a well-studied problem in quantum computing, and there are several implementations available.
For example, in the Qiskit library, the \texttt{AmplitudeEstimation} class can be used to perform amplitude estimation on a quantum circuit with a given number of qubits.
It assumes a \texttt{EstimationProblem} object is initialised with the quantum algorithm to be estimated and the objective qubit(s).

What is more, with binary rewards encoded in the final qubit, QMC can be implemented without the extra qubit that is described in \cref{sec:qmc}.
Instead, amplitude estimation can be performed directly on the oracles as they are implemented in \cref{alg:qucb_oracle}.
Additionally, since the number of iterations is described by QUCB, it is fed directly into the amplitude estimation simulation.
The MLE estimate is automagically calculated by the \texttt{AmplitudeEstimation} class, which will be used to update the QUCB estimate.
The number of oracle calls is also automatically tracked by the \texttt{AmplitudeEstimation} class, which is iterated by 1 to account for the initialisation of the oracle before amplitude estimation is performed.
In total, the QMC subroutine is implemented as in \cref{alg:qucb_qmc}.

\begin{algorithm}
    \SetAlgoLined
    \KwIn{Oracle $\mathcal{O}$, number of iterations $N$, confidence $\delta$}
    \KwOut{Estimate of $p$ with confidence $1-\delta$, number of oracle calls}
    Initialise \texttt{EstimationProblem} with oracle $\mathcal{O}$ and objective qubit 0 \;
    Number of shots $N_S \leftarrow \log(1 / \delta)$ \;
    Number of qubits $N_Q \leftarrow \lceil \log_2 N \rceil$ \;
    Initialise \texttt{AmplitudeEstimation} with number of shots $N_S$ and number of qubits $N_Q$ \;
    Estimate $p$ with \texttt{AmplitudeEstimation} on the \texttt{EstimationProblem} object \;
    $\hat{p} \leftarrow$ MLE result of \texttt{AmplitudeEstimation} \;
    $T \leftarrow$ number of iterations used by \texttt{AmplitudeEstimation} \;
    \Return $\hat{p}, T + 1$
    \caption{QMC for a Bernoulli arm oracle}
    \label{alg:qucb_qmc}
\end{algorithm}

\subsubsection{QUCB1 simulation}
Oracles and QMC being available, the QUCB1 algorithm can be implemented easily.
First, a set of oracles is initialised for each arm, and the algorithm is run for a given number of iterations.
The number of oracle calls is tracked, and the algorithm is stopped when the number of oracle calls exceeds the number of iterations.
Regret contributions are tracked and output after the simulation.
The simulation code thus appears as in \cref{alg:qucb1}.

\begin{algorithm}
    \SetAlgoLined
    \KwIn{
        Set of arm probabilities $\{p_1, \ldots, p_k\}$, \\
        number of iterations $T$, confidence $\delta$
    }
    \KwOut{Regret at each iteration}
    Initialise $t \leftarrow 0$ \;
    \For {$a \in \{1, \ldots, k\}$}{
        Initialise oracle $\mathcal{O}_a$ \;
        Initialise $\text{UCB}_a \leftarrow 1$ \;
        Initialise $N_a \leftarrow (C_1/\text{UCB}_a) \log(1/\delta)$ \;
        Estimate $\hat{\mu}_a$ with \cref{alg:qucb_qmc} \;
        Update $t$ with the number of oracle calls \;
        Log regret\;
    }
    \While {$t < T$}{
        $a \leftarrow \argmax_a (\hat{\mu}_a + \text{UCB}_a$ )\;
        $\text{UCB}_a \leftarrow \text{UCB}_a / 2$ \;
        $N_a \leftarrow (C_1/\text{UCB}_a) \log(1/\delta)$ \;
            Update estimate $\hat{\mu}_a$ with new estimate from \cref{alg:qucb_qmc} \;
            Update $t$ with the number of oracle calls \;
        Log regret\;
    }
    Discard any regret from excess turns \;
    \Return regrets $R_1, \ldots, R_T$
    \caption{QUCB1 simulation with a set of Bernoulli arms}
    \label{alg:qucb1_sim}
\end{algorithm}
